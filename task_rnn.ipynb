{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyJFmurm7JurlQM9nSFZiM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariabandeira/rn/blob/main/task_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset: [Credit card Details Binary Classification Problem](https://www.kaggle.com/datasets/rohitudageri/credit-card-details/)"
      ],
      "metadata": {
        "id": "DCdWDErpaJjP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh5u-SKYFFjq",
        "outputId": "df3fa147-8256-4ba0-fce0-51e6a576de79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n"
          ]
        }
      ],
      "source": [
        "# !pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "qGkePgCFFZ7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "2uyGpAbOYuSx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/Credit_card.csv\")\n",
        "dflabel = pd.read_csv(\"/content/Credit_card_label.csv\")"
      ],
      "metadata": {
        "id": "mI-Zh4-WFgHX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "lA5k-VSeL6S_",
        "outputId": "4a88be2d-0248-40d8-9dfb-7a0390e1264d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Ind_ID GENDER Car_Owner Propert_Owner  CHILDREN  Annual_income  \\\n",
              "0     5008827      M         Y             Y         0       180000.0   \n",
              "1     5009744      F         Y             N         0       315000.0   \n",
              "2     5009746      F         Y             N         0       315000.0   \n",
              "3     5009749      F         Y             N         0            NaN   \n",
              "4     5009752      F         Y             N         0       315000.0   \n",
              "...       ...    ...       ...           ...       ...            ...   \n",
              "1543  5028645      F         N             Y         0            NaN   \n",
              "1544  5023655      F         N             N         0       225000.0   \n",
              "1545  5115992      M         Y             Y         2       180000.0   \n",
              "1546  5118219      M         Y             N         0       270000.0   \n",
              "1547  5053790      F         Y             Y         0       225000.0   \n",
              "\n",
              "               Type_Income                      EDUCATION  \\\n",
              "0                Pensioner               Higher education   \n",
              "1     Commercial associate               Higher education   \n",
              "2     Commercial associate               Higher education   \n",
              "3     Commercial associate               Higher education   \n",
              "4     Commercial associate               Higher education   \n",
              "...                    ...                            ...   \n",
              "1543  Commercial associate               Higher education   \n",
              "1544  Commercial associate              Incomplete higher   \n",
              "1545               Working               Higher education   \n",
              "1546               Working  Secondary / secondary special   \n",
              "1547               Working               Higher education   \n",
              "\n",
              "            Marital_status       Housing_type  Birthday_count  Employed_days  \\\n",
              "0                  Married  House / apartment        -18772.0         365243   \n",
              "1                  Married  House / apartment        -13557.0           -586   \n",
              "2                  Married  House / apartment             NaN           -586   \n",
              "3                  Married  House / apartment        -13557.0           -586   \n",
              "4                  Married  House / apartment        -13557.0           -586   \n",
              "...                    ...                ...             ...            ...   \n",
              "1543               Married  House / apartment        -11957.0          -2182   \n",
              "1544  Single / not married  House / apartment        -10229.0          -1209   \n",
              "1545               Married  House / apartment        -13174.0          -2477   \n",
              "1546        Civil marriage  House / apartment        -15292.0           -645   \n",
              "1547               Married  House / apartment        -16601.0          -2859   \n",
              "\n",
              "      Mobile_phone  Work_Phone  Phone  EMAIL_ID Type_Occupation  \\\n",
              "0                1           0      0         0             NaN   \n",
              "1                1           1      1         0             NaN   \n",
              "2                1           1      1         0             NaN   \n",
              "3                1           1      1         0             NaN   \n",
              "4                1           1      1         0             NaN   \n",
              "...            ...         ...    ...       ...             ...   \n",
              "1543             1           0      0         0        Managers   \n",
              "1544             1           0      0         0     Accountants   \n",
              "1545             1           0      0         0        Managers   \n",
              "1546             1           1      1         0         Drivers   \n",
              "1547             1           0      0         0             NaN   \n",
              "\n",
              "      Family_Members  \n",
              "0                  2  \n",
              "1                  2  \n",
              "2                  2  \n",
              "3                  2  \n",
              "4                  2  \n",
              "...              ...  \n",
              "1543               2  \n",
              "1544               1  \n",
              "1545               4  \n",
              "1546               2  \n",
              "1547               2  \n",
              "\n",
              "[1548 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e5f7b50-01be-4ab7-ad7a-557f516cbda5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ind_ID</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>Car_Owner</th>\n",
              "      <th>Propert_Owner</th>\n",
              "      <th>CHILDREN</th>\n",
              "      <th>Annual_income</th>\n",
              "      <th>Type_Income</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>Marital_status</th>\n",
              "      <th>Housing_type</th>\n",
              "      <th>Birthday_count</th>\n",
              "      <th>Employed_days</th>\n",
              "      <th>Mobile_phone</th>\n",
              "      <th>Work_Phone</th>\n",
              "      <th>Phone</th>\n",
              "      <th>EMAIL_ID</th>\n",
              "      <th>Type_Occupation</th>\n",
              "      <th>Family_Members</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5008827</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>Pensioner</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-18772.0</td>\n",
              "      <td>365243</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5009744</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>315000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-13557.0</td>\n",
              "      <td>-586</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5009746</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>315000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-586</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5009749</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-13557.0</td>\n",
              "      <td>-586</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5009752</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>315000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-13557.0</td>\n",
              "      <td>-586</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1543</th>\n",
              "      <td>5028645</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-11957.0</td>\n",
              "      <td>-2182</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1544</th>\n",
              "      <td>5023655</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Incomplete higher</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-10229.0</td>\n",
              "      <td>-1209</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Accountants</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1545</th>\n",
              "      <td>5115992</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>2</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-13174.0</td>\n",
              "      <td>-2477</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1546</th>\n",
              "      <td>5118219</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-15292.0</td>\n",
              "      <td>-645</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Drivers</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1547</th>\n",
              "      <td>5053790</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-16601.0</td>\n",
              "      <td>-2859</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1548 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e5f7b50-01be-4ab7-ad7a-557f516cbda5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e5f7b50-01be-4ab7-ad7a-557f516cbda5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e5f7b50-01be-4ab7-ad7a-557f516cbda5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db284e4e-6234-4da5-ab72-bc7fa99cf8f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db284e4e-6234-4da5-ab72-bc7fa99cf8f7')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db284e4e-6234-4da5-ab72-bc7fa99cf8f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dflabel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "oU4DL1rXL8q9",
        "outputId": "a364e9ba-27fd-41c2-bce5-7ad76efa95fc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Ind_ID  label\n",
              "0     5008827      1\n",
              "1     5009744      1\n",
              "2     5009746      1\n",
              "3     5009749      1\n",
              "4     5009752      1\n",
              "...       ...    ...\n",
              "1543  5028645      0\n",
              "1544  5023655      0\n",
              "1545  5115992      0\n",
              "1546  5118219      0\n",
              "1547  5053790      0\n",
              "\n",
              "[1548 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86aebcfb-77bc-4aae-83a8-fdf9032df702\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ind_ID</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5008827</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5009744</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5009746</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5009749</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5009752</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1543</th>\n",
              "      <td>5028645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1544</th>\n",
              "      <td>5023655</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1545</th>\n",
              "      <td>5115992</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1546</th>\n",
              "      <td>5118219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1547</th>\n",
              "      <td>5053790</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1548 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86aebcfb-77bc-4aae-83a8-fdf9032df702')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86aebcfb-77bc-4aae-83a8-fdf9032df702 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86aebcfb-77bc-4aae-83a8-fdf9032df702');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bddc812a-a10d-41aa-b684-a8bb46f01da8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bddc812a-a10d-41aa-b684-a8bb46f01da8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bddc812a-a10d-41aa-b684-a8bb46f01da8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df\n",
        "Y = dflabel['label']"
      ],
      "metadata": {
        "id": "ZWtXWI3cMTbm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "jQS4WQjBMc5k"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['CHILDREN'].dtype == int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z51avILNnKq",
        "outputId": "6ccb8191-24e1-4793-929c-3876b0604afa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT2cPGUvO7ee",
        "outputId": "70fffb5b-2036-4ef3-b5db-65a752cab87d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1548 entries, 0 to 1547\n",
            "Data columns (total 18 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Ind_ID           1548 non-null   int64  \n",
            " 1   GENDER           1541 non-null   object \n",
            " 2   Car_Owner        1548 non-null   object \n",
            " 3   Propert_Owner    1548 non-null   object \n",
            " 4   CHILDREN         1548 non-null   int64  \n",
            " 5   Annual_income    1525 non-null   float64\n",
            " 6   Type_Income      1548 non-null   object \n",
            " 7   EDUCATION        1548 non-null   object \n",
            " 8   Marital_status   1548 non-null   object \n",
            " 9   Housing_type     1548 non-null   object \n",
            " 10  Birthday_count   1526 non-null   float64\n",
            " 11  Employed_days    1548 non-null   int64  \n",
            " 12  Mobile_phone     1548 non-null   int64  \n",
            " 13  Work_Phone       1548 non-null   int64  \n",
            " 14  Phone            1548 non-null   int64  \n",
            " 15  EMAIL_ID         1548 non-null   int64  \n",
            " 16  Type_Occupation  1060 non-null   object \n",
            " 17  Family_Members   1548 non-null   int64  \n",
            "dtypes: float64(2), int64(8), object(8)\n",
            "memory usage: 217.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in X.columns:\n",
        "    tranformer = LabelEncoder()\n",
        "    if X[column].dtype == object:\n",
        "        X[column] = tranformer.fit_transform(X[column])"
      ],
      "metadata": {
        "id": "kMf57jQdNglg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "3o9HUwmnQGbA",
        "outputId": "3e8c2da5-9a19-4583-b2f2-f9a896a333ba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Ind_ID  GENDER  Car_Owner  Propert_Owner  CHILDREN  Annual_income  \\\n",
              "0     5008827       1          1              1         0       180000.0   \n",
              "1     5009744       0          1              0         0       315000.0   \n",
              "2     5009746       0          1              0         0       315000.0   \n",
              "3     5009749       0          1              0         0            NaN   \n",
              "4     5009752       0          1              0         0       315000.0   \n",
              "...       ...     ...        ...            ...       ...            ...   \n",
              "1543  5028645       0          0              1         0            NaN   \n",
              "1544  5023655       0          0              0         0       225000.0   \n",
              "1545  5115992       1          1              1         2       180000.0   \n",
              "1546  5118219       1          1              0         0       270000.0   \n",
              "1547  5053790       0          1              1         0       225000.0   \n",
              "\n",
              "      Type_Income  EDUCATION  Marital_status  Housing_type  Birthday_count  \\\n",
              "0               1          1               1             1        -18772.0   \n",
              "1               0          1               1             1        -13557.0   \n",
              "2               0          1               1             1             NaN   \n",
              "3               0          1               1             1        -13557.0   \n",
              "4               0          1               1             1        -13557.0   \n",
              "...           ...        ...             ...           ...             ...   \n",
              "1543            0          1               1             1        -11957.0   \n",
              "1544            0          2               3             1        -10229.0   \n",
              "1545            3          1               1             1        -13174.0   \n",
              "1546            3          4               0             1        -15292.0   \n",
              "1547            3          1               1             1        -16601.0   \n",
              "\n",
              "      Employed_days  Mobile_phone  Work_Phone  Phone  EMAIL_ID  \\\n",
              "0            365243             1           0      0         0   \n",
              "1              -586             1           1      1         0   \n",
              "2              -586             1           1      1         0   \n",
              "3              -586             1           1      1         0   \n",
              "4              -586             1           1      1         0   \n",
              "...             ...           ...         ...    ...       ...   \n",
              "1543          -2182             1           0      0         0   \n",
              "1544          -1209             1           0      0         0   \n",
              "1545          -2477             1           0      0         0   \n",
              "1546           -645             1           1      1         0   \n",
              "1547          -2859             1           0      0         0   \n",
              "\n",
              "      Type_Occupation  Family_Members  \n",
              "0                  18               2  \n",
              "1                  18               2  \n",
              "2                  18               2  \n",
              "3                  18               2  \n",
              "4                  18               2  \n",
              "...               ...             ...  \n",
              "1543               10               2  \n",
              "1544                0               1  \n",
              "1545               10               4  \n",
              "1546                4               2  \n",
              "1547               18               2  \n",
              "\n",
              "[1548 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63f3575e-89dd-4254-80e9-2cdc12541c82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ind_ID</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>Car_Owner</th>\n",
              "      <th>Propert_Owner</th>\n",
              "      <th>CHILDREN</th>\n",
              "      <th>Annual_income</th>\n",
              "      <th>Type_Income</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>Marital_status</th>\n",
              "      <th>Housing_type</th>\n",
              "      <th>Birthday_count</th>\n",
              "      <th>Employed_days</th>\n",
              "      <th>Mobile_phone</th>\n",
              "      <th>Work_Phone</th>\n",
              "      <th>Phone</th>\n",
              "      <th>EMAIL_ID</th>\n",
              "      <th>Type_Occupation</th>\n",
              "      <th>Family_Members</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5008827</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-18772.0</td>\n",
              "      <td>365243</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5009744</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-13557.0</td>\n",
              "      <td>-586</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5009746</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-586</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5009749</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-13557.0</td>\n",
              "      <td>-586</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5009752</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-13557.0</td>\n",
              "      <td>-586</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1543</th>\n",
              "      <td>5028645</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-11957.0</td>\n",
              "      <td>-2182</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1544</th>\n",
              "      <td>5023655</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-10229.0</td>\n",
              "      <td>-1209</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1545</th>\n",
              "      <td>5115992</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-13174.0</td>\n",
              "      <td>-2477</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1546</th>\n",
              "      <td>5118219</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-15292.0</td>\n",
              "      <td>-645</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1547</th>\n",
              "      <td>5053790</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-16601.0</td>\n",
              "      <td>-2859</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1548 rows × 18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f3575e-89dd-4254-80e9-2cdc12541c82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63f3575e-89dd-4254-80e9-2cdc12541c82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63f3575e-89dd-4254-80e9-2cdc12541c82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5af9b594-3b95-41d6-8b1c-694b68b17699\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5af9b594-3b95-41d6-8b1c-694b68b17699')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5af9b594-3b95-41d6-8b1c-694b68b17699 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.isnull().sum()"
      ],
      "metadata": {
        "id": "a_r4t3dERp_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.dropna()"
      ],
      "metadata": {
        "id": "6YNFJTq9R3vU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4S6JuQaSHbP",
        "outputId": "64787c23-fd25-4a0e-cf3e-ad3bac722938"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1503 entries, 0 to 1547\n",
            "Data columns (total 18 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Ind_ID           1503 non-null   int64  \n",
            " 1   GENDER           1503 non-null   int64  \n",
            " 2   Car_Owner        1503 non-null   int64  \n",
            " 3   Propert_Owner    1503 non-null   int64  \n",
            " 4   CHILDREN         1503 non-null   int64  \n",
            " 5   Annual_income    1503 non-null   float64\n",
            " 6   Type_Income      1503 non-null   int64  \n",
            " 7   EDUCATION        1503 non-null   int64  \n",
            " 8   Marital_status   1503 non-null   int64  \n",
            " 9   Housing_type     1503 non-null   int64  \n",
            " 10  Birthday_count   1503 non-null   float64\n",
            " 11  Employed_days    1503 non-null   int64  \n",
            " 12  Mobile_phone     1503 non-null   int64  \n",
            " 13  Work_Phone       1503 non-null   int64  \n",
            " 14  Phone            1503 non-null   int64  \n",
            " 15  EMAIL_ID         1503 non-null   int64  \n",
            " 16  Type_Occupation  1503 non-null   int64  \n",
            " 17  Family_Members   1503 non-null   int64  \n",
            "dtypes: float64(2), int64(16)\n",
            "memory usage: 223.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X['Ind_ID'].value_counts().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-CaAD6qSsaw",
        "outputId": "0ed55d43-ce55-4aa6-e149-319acaa32731"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1503"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_merged = pd.merge(X, dflabel, on='Ind_ID')"
      ],
      "metadata": {
        "id": "0DkgZiKoSaHy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = y_merged['label']"
      ],
      "metadata": {
        "id": "YO_W9e8BTUZi"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separando dados de treino e teste"
      ],
      "metadata": {
        "id": "iYqmMkBPTwKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "7TwsYUB2TtlY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=26)"
      ],
      "metadata": {
        "id": "13lvexeTUCm_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('treinamento:', len(y_train))\n",
        "print('teste      :', len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7StH6EmwUK4j",
        "outputId": "29d3503a-5c64-47c6-f299-65c6282928c9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treinamento: 1052\n",
            "teste      : 451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N66jNYqVU7xo",
        "outputId": "927ac1d5-4037-4233-e803-dcafa606c024"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras"
      ],
      "metadata": {
        "id": "n-nhiZpZZe_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link](https://www.youtube.com/watch?v=SVlsK2goeoI)"
      ],
      "metadata": {
        "id": "7qrw_4LXZj3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "#Criando a arquitetura da rede neural\n",
        "modelo = Sequential()\n",
        "modelo.add(Dense(units=3, activation='relu', input_dim=X_train.shape[1]))\n",
        "modelo.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "#Treinando a rede neural\n",
        "modelo.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "resultado = modelo.fit(X_train, y_train, epochs=1000, batch_size=52, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXa1uOftUK15",
        "outputId": "5a9bb0eb-f5d2-498d-91e0-0cbdd4107579"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "21/21 [==============================] - 1s 10ms/step - loss: 5467326119936.0000 - mae: 2336726.5000 - val_loss: 4990282760192.0000 - val_mae: 2232887.2500\n",
            "Epoch 2/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4601906987008.0000 - mae: 2143534.0000 - val_loss: 4163305734144.0000 - val_mae: 2039392.5000\n",
            "Epoch 3/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3819718836224.0000 - mae: 1952659.3750 - val_loss: 3433888219136.0000 - val_mae: 1852009.6250\n",
            "Epoch 4/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3133875683328.0000 - mae: 1768424.2500 - val_loss: 2797821493248.0000 - val_mae: 1671532.1250\n",
            "Epoch 5/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2538000089088.0000 - mae: 1591174.8750 - val_loss: 2248125448192.0000 - val_mae: 1498119.3750\n",
            "Epoch 6/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2025285746688.0000 - mae: 1421157.0000 - val_loss: 1777948295168.0000 - val_mae: 1331970.7500\n",
            "Epoch 7/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1589206188032.0000 - mae: 1258438.5000 - val_loss: 1380754128896.0000 - val_mae: 1173402.5000\n",
            "Epoch 8/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1223543226368.0000 - mae: 1103630.0000 - val_loss: 1051074887680.0000 - val_mae: 1023263.2500\n",
            "Epoch 9/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 922454851584.0000 - mae: 957669.6250 - val_loss: 782648737792.0000 - val_mae: 882314.6250\n",
            "Epoch 10/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 679776288768.0000 - mae: 821238.1875 - val_loss: 569050660864.0000 - val_mae: 751458.0625\n",
            "Epoch 11/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 488671084544.0000 - mae: 695232.0000 - val_loss: 403204472832.0000 - val_mae: 631382.1250\n",
            "Epoch 12/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 342155788288.0000 - mae: 580708.4375 - val_loss: 278590816256.0000 - val_mae: 523440.3438\n",
            "Epoch 13/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 233454862336.0000 - mae: 478248.0625 - val_loss: 187476017152.0000 - val_mae: 427935.9062\n",
            "Epoch 14/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 155193114624.0000 - mae: 388019.3125 - val_loss: 122972913664.0000 - val_mae: 344466.9062\n",
            "Epoch 15/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 100625866752.0000 - mae: 310060.8750 - val_loss: 79037865984.0000 - val_mae: 273698.9062\n",
            "Epoch 16/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 63951831040.0000 - mae: 244202.7344 - val_loss: 50168573952.0000 - val_mae: 214901.3750\n",
            "Epoch 17/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 40142635008.0000 - mae: 190089.7969 - val_loss: 31880794112.0000 - val_mae: 167000.6094\n",
            "Epoch 18/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 25330241536.0000 - mae: 146730.6250 - val_loss: 20706004992.0000 - val_mae: 129669.1875\n",
            "Epoch 19/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 16398142464.0000 - mae: 113605.8359 - val_loss: 14064178176.0000 - val_mae: 102125.0547\n",
            "Epoch 20/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 11152241664.0000 - mae: 89338.0781 - val_loss: 10176476160.0000 - val_mae: 82333.4375\n",
            "Epoch 21/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8129414656.0000 - mae: 72883.7344 - val_loss: 8088260096.0000 - val_mae: 69721.7031\n",
            "Epoch 22/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 6520623616.0000 - mae: 62312.1992 - val_loss: 6934000640.0000 - val_mae: 61308.4375\n",
            "Epoch 23/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 5640711680.0000 - mae: 55746.0391 - val_loss: 6343234560.0000 - val_mae: 56473.5078\n",
            "Epoch 24/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 5183032320.0000 - mae: 52174.2109 - val_loss: 5996811776.0000 - val_mae: 53490.1719\n",
            "Epoch 25/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4912695296.0000 - mae: 49900.1445 - val_loss: 5794292224.0000 - val_mae: 51730.4727\n",
            "Epoch 26/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4755074560.0000 - mae: 48581.5000 - val_loss: 5670851072.0000 - val_mae: 50530.2500\n",
            "Epoch 27/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4653807616.0000 - mae: 47727.7695 - val_loss: 5583359488.0000 - val_mae: 49740.9180\n",
            "Epoch 28/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4579411968.0000 - mae: 47203.3477 - val_loss: 5511552512.0000 - val_mae: 49252.1875\n",
            "Epoch 29/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4517743616.0000 - mae: 46835.4609 - val_loss: 5446718976.0000 - val_mae: 48888.4883\n",
            "Epoch 30/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4458135040.0000 - mae: 46494.9766 - val_loss: 5381628416.0000 - val_mae: 48492.5977\n",
            "Epoch 31/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4400425984.0000 - mae: 46149.0703 - val_loss: 5316188672.0000 - val_mae: 48122.8438\n",
            "Epoch 32/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4343314944.0000 - mae: 45827.3164 - val_loss: 5252691456.0000 - val_mae: 47789.6172\n",
            "Epoch 33/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4287055104.0000 - mae: 45516.2188 - val_loss: 5189377024.0000 - val_mae: 47441.3750\n",
            "Epoch 34/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4229015552.0000 - mae: 45195.3398 - val_loss: 5126404608.0000 - val_mae: 47148.7227\n",
            "Epoch 35/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4173324800.0000 - mae: 44927.5312 - val_loss: 5060812800.0000 - val_mae: 46892.9180\n",
            "Epoch 36/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4115924992.0000 - mae: 44598.1641 - val_loss: 5001002496.0000 - val_mae: 46540.5352\n",
            "Epoch 37/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4062072320.0000 - mae: 44272.2305 - val_loss: 4937184256.0000 - val_mae: 46171.7305\n",
            "Epoch 38/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4005228800.0000 - mae: 43966.2422 - val_loss: 4873716736.0000 - val_mae: 45927.9102\n",
            "Epoch 39/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3950961152.0000 - mae: 43673.2422 - val_loss: 4809397248.0000 - val_mae: 45607.0742\n",
            "Epoch 40/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3893824512.0000 - mae: 43357.6172 - val_loss: 4748243968.0000 - val_mae: 45304.8203\n",
            "Epoch 41/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3840123648.0000 - mae: 43046.5625 - val_loss: 4684919296.0000 - val_mae: 44969.4062\n",
            "Epoch 42/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3783863808.0000 - mae: 42734.3398 - val_loss: 4621301760.0000 - val_mae: 44694.6211\n",
            "Epoch 43/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3728348416.0000 - mae: 42426.1562 - val_loss: 4560367104.0000 - val_mae: 44391.7344\n",
            "Epoch 44/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3677063424.0000 - mae: 42124.0820 - val_loss: 4498063360.0000 - val_mae: 44061.8789\n",
            "Epoch 45/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3623883776.0000 - mae: 41769.7930 - val_loss: 4437741568.0000 - val_mae: 43700.2070\n",
            "Epoch 46/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3569483520.0000 - mae: 41463.7383 - val_loss: 4378403328.0000 - val_mae: 43412.7148\n",
            "Epoch 47/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3520086784.0000 - mae: 41196.6289 - val_loss: 4315427328.0000 - val_mae: 43149.1289\n",
            "Epoch 48/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3465986816.0000 - mae: 40868.1133 - val_loss: 4255980544.0000 - val_mae: 42791.2188\n",
            "Epoch 49/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3411698432.0000 - mae: 40522.6055 - val_loss: 4199054080.0000 - val_mae: 42477.9336\n",
            "Epoch 50/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3362818048.0000 - mae: 40229.1836 - val_loss: 4136687872.0000 - val_mae: 42185.9219\n",
            "Epoch 51/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3307966208.0000 - mae: 39894.0820 - val_loss: 4076697344.0000 - val_mae: 41865.7305\n",
            "Epoch 52/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3258672384.0000 - mae: 39641.0273 - val_loss: 4017570304.0000 - val_mae: 41650.2930\n",
            "Epoch 53/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3207271680.0000 - mae: 39348.5664 - val_loss: 3960320768.0000 - val_mae: 41313.2891\n",
            "Epoch 54/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3159204096.0000 - mae: 38976.5000 - val_loss: 3906876416.0000 - val_mae: 40875.2031\n",
            "Epoch 55/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3110799360.0000 - mae: 38659.9375 - val_loss: 3849795584.0000 - val_mae: 40671.4180\n",
            "Epoch 56/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3063438592.0000 - mae: 38340.7148 - val_loss: 3794575104.0000 - val_mae: 40275.3750\n",
            "Epoch 57/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3006389504.0000 - mae: 38114.7383 - val_loss: 3728363008.0000 - val_mae: 40223.6602\n",
            "Epoch 58/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2960085248.0000 - mae: 37911.0391 - val_loss: 3671481856.0000 - val_mae: 39898.3047\n",
            "Epoch 59/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2912276480.0000 - mae: 37467.9883 - val_loss: 3615485440.0000 - val_mae: 39324.6992\n",
            "Epoch 60/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2866597888.0000 - mae: 37096.0898 - val_loss: 3561044992.0000 - val_mae: 39022.7109\n",
            "Epoch 61/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2820150272.0000 - mae: 36789.9609 - val_loss: 3510231552.0000 - val_mae: 38721.6523\n",
            "Epoch 62/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2777391360.0000 - mae: 36406.7500 - val_loss: 3459988736.0000 - val_mae: 38326.0391\n",
            "Epoch 63/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2733408256.0000 - mae: 36133.0430 - val_loss: 3408711424.0000 - val_mae: 38101.6055\n",
            "Epoch 64/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2691733760.0000 - mae: 35837.4297 - val_loss: 3356387840.0000 - val_mae: 37731.3242\n",
            "Epoch 65/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2647957504.0000 - mae: 35477.6797 - val_loss: 3310303488.0000 - val_mae: 37394.5352\n",
            "Epoch 66/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2608618752.0000 - mae: 35168.6562 - val_loss: 3260525312.0000 - val_mae: 37122.7969\n",
            "Epoch 67/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2568595968.0000 - mae: 35010.7305 - val_loss: 3210429696.0000 - val_mae: 36980.7344\n",
            "Epoch 68/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2527259392.0000 - mae: 34647.4492 - val_loss: 3166905088.0000 - val_mae: 36569.6562\n",
            "Epoch 69/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2488381440.0000 - mae: 34429.0586 - val_loss: 3114219520.0000 - val_mae: 36390.1602\n",
            "Epoch 70/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2446842368.0000 - mae: 34091.0312 - val_loss: 3070625536.0000 - val_mae: 36031.4883\n",
            "Epoch 71/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2410109952.0000 - mae: 33949.9766 - val_loss: 3021776896.0000 - val_mae: 35945.7617\n",
            "Epoch 72/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2370324992.0000 - mae: 33599.8828 - val_loss: 2979062272.0000 - val_mae: 35483.1133\n",
            "Epoch 73/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2335791872.0000 - mae: 33333.3633 - val_loss: 2931475456.0000 - val_mae: 35266.7344\n",
            "Epoch 74/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2296377088.0000 - mae: 32935.3320 - val_loss: 2888325632.0000 - val_mae: 34834.4180\n",
            "Epoch 75/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2259461888.0000 - mae: 32707.1074 - val_loss: 2842990592.0000 - val_mae: 34716.8047\n",
            "Epoch 76/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2225563904.0000 - mae: 32399.4531 - val_loss: 2803106560.0000 - val_mae: 34278.8320\n",
            "Epoch 77/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2189309696.0000 - mae: 32148.9160 - val_loss: 2760733696.0000 - val_mae: 34097.8633\n",
            "Epoch 78/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2156319744.0000 - mae: 31996.6387 - val_loss: 2718371072.0000 - val_mae: 33902.6367\n",
            "Epoch 79/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2121465344.0000 - mae: 31643.4414 - val_loss: 2676777472.0000 - val_mae: 33505.0117\n",
            "Epoch 80/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2088679552.0000 - mae: 31308.2500 - val_loss: 2635807232.0000 - val_mae: 33215.7773\n",
            "Epoch 81/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2054352384.0000 - mae: 31194.1758 - val_loss: 2594820864.0000 - val_mae: 33179.0898\n",
            "Epoch 82/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2022685952.0000 - mae: 31022.1914 - val_loss: 2553607936.0000 - val_mae: 32853.6523\n",
            "Epoch 83/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1988900352.0000 - mae: 30669.7363 - val_loss: 2513137152.0000 - val_mae: 32492.9531\n",
            "Epoch 84/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1957934080.0000 - mae: 30369.2832 - val_loss: 2473968640.0000 - val_mae: 32195.7266\n",
            "Epoch 85/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1925935872.0000 - mae: 30057.9043 - val_loss: 2437557248.0000 - val_mae: 31939.4941\n",
            "Epoch 86/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1895611008.0000 - mae: 29818.8203 - val_loss: 2399698944.0000 - val_mae: 31659.3965\n",
            "Epoch 87/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1866794752.0000 - mae: 29491.7109 - val_loss: 2366248960.0000 - val_mae: 31329.0918\n",
            "Epoch 88/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1836447872.0000 - mae: 29218.3574 - val_loss: 2331202816.0000 - val_mae: 31027.9473\n",
            "Epoch 89/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1808745216.0000 - mae: 29050.9219 - val_loss: 2290577664.0000 - val_mae: 30958.0586\n",
            "Epoch 90/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1780697472.0000 - mae: 28788.6641 - val_loss: 2255917312.0000 - val_mae: 30533.7148\n",
            "Epoch 91/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1749293568.0000 - mae: 28582.3066 - val_loss: 2221123840.0000 - val_mae: 30405.6191\n",
            "Epoch 92/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1723213440.0000 - mae: 28346.7207 - val_loss: 2185232896.0000 - val_mae: 30141.6855\n",
            "Epoch 93/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1694299776.0000 - mae: 28135.9902 - val_loss: 2151423744.0000 - val_mae: 29878.0195\n",
            "Epoch 94/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1668525312.0000 - mae: 27808.5723 - val_loss: 2117086464.0000 - val_mae: 29552.7012\n",
            "Epoch 95/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1643127552.0000 - mae: 27515.0000 - val_loss: 2083829760.0000 - val_mae: 29297.1426\n",
            "Epoch 96/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1614343680.0000 - mae: 27329.6094 - val_loss: 2049687424.0000 - val_mae: 29055.1699\n",
            "Epoch 97/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1587337984.0000 - mae: 27128.8340 - val_loss: 2016465408.0000 - val_mae: 28864.7656\n",
            "Epoch 98/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1561604736.0000 - mae: 26886.9805 - val_loss: 1985792000.0000 - val_mae: 28554.4570\n",
            "Epoch 99/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1540870784.0000 - mae: 26793.8965 - val_loss: 1951450752.0000 - val_mae: 28469.2793\n",
            "Epoch 100/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1510624768.0000 - mae: 26486.8594 - val_loss: 1920096384.0000 - val_mae: 28046.0137\n",
            "Epoch 101/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1486046208.0000 - mae: 26186.5527 - val_loss: 1887332224.0000 - val_mae: 27846.0605\n",
            "Epoch 102/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1460781056.0000 - mae: 26140.4512 - val_loss: 1856526080.0000 - val_mae: 27743.7969\n",
            "Epoch 103/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1436395904.0000 - mae: 25832.1211 - val_loss: 1823628800.0000 - val_mae: 27352.4238\n",
            "Epoch 104/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1410628608.0000 - mae: 25514.1113 - val_loss: 1793168768.0000 - val_mae: 26996.5312\n",
            "Epoch 105/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1388050944.0000 - mae: 25174.4336 - val_loss: 1765485952.0000 - val_mae: 26726.8848\n",
            "Epoch 106/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1364562944.0000 - mae: 25004.6602 - val_loss: 1735875968.0000 - val_mae: 26560.2070\n",
            "Epoch 107/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1340406912.0000 - mae: 24891.3828 - val_loss: 1707664000.0000 - val_mae: 26430.3809\n",
            "Epoch 108/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1318620288.0000 - mae: 24794.4004 - val_loss: 1676711424.0000 - val_mae: 26267.6660\n",
            "Epoch 109/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1295528960.0000 - mae: 24508.3613 - val_loss: 1646843776.0000 - val_mae: 25972.7012\n",
            "Epoch 110/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1271919104.0000 - mae: 24234.0977 - val_loss: 1617590656.0000 - val_mae: 25663.8184\n",
            "Epoch 111/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1249939712.0000 - mae: 24002.6660 - val_loss: 1588665856.0000 - val_mae: 25398.7695\n",
            "Epoch 112/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1228357888.0000 - mae: 23741.5293 - val_loss: 1560594944.0000 - val_mae: 25147.5449\n",
            "Epoch 113/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1205988608.0000 - mae: 23496.8535 - val_loss: 1535515392.0000 - val_mae: 24891.4648\n",
            "Epoch 114/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1187165312.0000 - mae: 23414.1074 - val_loss: 1505715328.0000 - val_mae: 24832.2070\n",
            "Epoch 115/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1164411392.0000 - mae: 23197.2969 - val_loss: 1479236608.0000 - val_mae: 24458.4961\n",
            "Epoch 116/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1143371776.0000 - mae: 22838.2734 - val_loss: 1453745536.0000 - val_mae: 24194.6348\n",
            "Epoch 117/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1122592000.0000 - mae: 22787.0098 - val_loss: 1426936960.0000 - val_mae: 24187.1543\n",
            "Epoch 118/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1102474496.0000 - mae: 22488.9961 - val_loss: 1402376576.0000 - val_mae: 23695.3770\n",
            "Epoch 119/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1084523264.0000 - mae: 22317.1426 - val_loss: 1373416192.0000 - val_mae: 23590.7832\n",
            "Epoch 120/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1061977344.0000 - mae: 22019.1406 - val_loss: 1350267904.0000 - val_mae: 23255.1465\n",
            "Epoch 121/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1042446336.0000 - mae: 21864.2402 - val_loss: 1322790656.0000 - val_mae: 23167.1328\n",
            "Epoch 122/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1022708736.0000 - mae: 21614.7246 - val_loss: 1299825536.0000 - val_mae: 22842.9492\n",
            "Epoch 123/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1003944960.0000 - mae: 21391.1270 - val_loss: 1274809216.0000 - val_mae: 22665.8203\n",
            "Epoch 124/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 985371136.0000 - mae: 21360.3164 - val_loss: 1249478272.0000 - val_mae: 22638.6211\n",
            "Epoch 125/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 965943680.0000 - mae: 21120.0449 - val_loss: 1225504768.0000 - val_mae: 22269.6016\n",
            "Epoch 126/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 946445888.0000 - mae: 20885.0879 - val_loss: 1202488064.0000 - val_mae: 22018.9375\n",
            "Epoch 127/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 930590208.0000 - mae: 20741.2910 - val_loss: 1176685696.0000 - val_mae: 21842.7734\n",
            "Epoch 128/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 910448832.0000 - mae: 20399.4141 - val_loss: 1153950720.0000 - val_mae: 21534.8594\n",
            "Epoch 129/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 892828416.0000 - mae: 20170.1953 - val_loss: 1130923904.0000 - val_mae: 21270.3750\n",
            "Epoch 130/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 874614144.0000 - mae: 19933.2910 - val_loss: 1109481344.0000 - val_mae: 21047.9414\n",
            "Epoch 131/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 857489856.0000 - mae: 19820.0430 - val_loss: 1086046848.0000 - val_mae: 20918.4277\n",
            "Epoch 132/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 839470848.0000 - mae: 19638.4883 - val_loss: 1064176768.0000 - val_mae: 20732.0840\n",
            "Epoch 133/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 822445568.0000 - mae: 19436.7754 - val_loss: 1043213696.0000 - val_mae: 20503.0820\n",
            "Epoch 134/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 806495808.0000 - mae: 19166.7246 - val_loss: 1021009472.0000 - val_mae: 20167.8730\n",
            "Epoch 135/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 789620928.0000 - mae: 19028.4297 - val_loss: 998664832.0000 - val_mae: 20107.2070\n",
            "Epoch 136/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 772806272.0000 - mae: 18765.5664 - val_loss: 980452416.0000 - val_mae: 19687.8828\n",
            "Epoch 137/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 756299712.0000 - mae: 18560.4902 - val_loss: 957308864.0000 - val_mae: 19629.3477\n",
            "Epoch 138/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 740231872.0000 - mae: 18565.5352 - val_loss: 936660928.0000 - val_mae: 19610.5547\n",
            "Epoch 139/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 724067904.0000 - mae: 18265.6660 - val_loss: 917024192.0000 - val_mae: 19155.1152\n",
            "Epoch 140/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 709713216.0000 - mae: 18098.8828 - val_loss: 894814976.0000 - val_mae: 19012.5352\n",
            "Epoch 141/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 691128064.0000 - mae: 17836.5332 - val_loss: 873419008.0000 - val_mae: 18756.2852\n",
            "Epoch 142/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 675375616.0000 - mae: 17630.1621 - val_loss: 853431296.0000 - val_mae: 18587.6074\n",
            "Epoch 143/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 660630144.0000 - mae: 17361.6211 - val_loss: 835661312.0000 - val_mae: 18252.6055\n",
            "Epoch 144/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 645525504.0000 - mae: 17314.6250 - val_loss: 815233664.0000 - val_mae: 18219.6445\n",
            "Epoch 145/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 630552384.0000 - mae: 17028.7891 - val_loss: 796526784.0000 - val_mae: 17915.6113\n",
            "Epoch 146/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 613646720.0000 - mae: 17018.9961 - val_loss: 774638592.0000 - val_mae: 17952.1211\n",
            "Epoch 147/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 597858368.0000 - mae: 16795.7441 - val_loss: 754558080.0000 - val_mae: 17522.2441\n",
            "Epoch 148/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 583233216.0000 - mae: 16403.0020 - val_loss: 735342336.0000 - val_mae: 17198.3164\n",
            "Epoch 149/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 568688128.0000 - mae: 16106.9600 - val_loss: 718705728.0000 - val_mae: 16942.7891\n",
            "Epoch 150/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 555344320.0000 - mae: 15978.6250 - val_loss: 700143040.0000 - val_mae: 16816.0742\n",
            "Epoch 151/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 541531648.0000 - mae: 15769.4912 - val_loss: 684768064.0000 - val_mae: 16560.1250\n",
            "Epoch 152/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 528855840.0000 - mae: 15580.5889 - val_loss: 666150144.0000 - val_mae: 16450.3828\n",
            "Epoch 153/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 515273056.0000 - mae: 15419.3711 - val_loss: 649445504.0000 - val_mae: 16148.5928\n",
            "Epoch 154/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 501938176.0000 - mae: 15207.4141 - val_loss: 633595264.0000 - val_mae: 16022.3779\n",
            "Epoch 155/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 489592640.0000 - mae: 15040.7197 - val_loss: 617339072.0000 - val_mae: 15776.6445\n",
            "Epoch 156/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 477367296.0000 - mae: 14854.8096 - val_loss: 600931776.0000 - val_mae: 15577.2695\n",
            "Epoch 157/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 465108288.0000 - mae: 14685.0381 - val_loss: 585149312.0000 - val_mae: 15381.9023\n",
            "Epoch 158/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 452640352.0000 - mae: 14444.2178 - val_loss: 570454528.0000 - val_mae: 15147.7158\n",
            "Epoch 159/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 441444960.0000 - mae: 14294.6191 - val_loss: 554552576.0000 - val_mae: 14999.7461\n",
            "Epoch 160/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 429155808.0000 - mae: 14042.1182 - val_loss: 540076160.0000 - val_mae: 14701.7783\n",
            "Epoch 161/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 418198592.0000 - mae: 13952.3672 - val_loss: 524662752.0000 - val_mae: 14622.9746\n",
            "Epoch 162/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 406367648.0000 - mae: 13728.3154 - val_loss: 509738048.0000 - val_mae: 14352.7510\n",
            "Epoch 163/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 395068384.0000 - mae: 13444.6553 - val_loss: 495783328.0000 - val_mae: 14143.6963\n",
            "Epoch 164/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 383379008.0000 - mae: 13305.1650 - val_loss: 482933920.0000 - val_mae: 13977.9121\n",
            "Epoch 165/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 373168832.0000 - mae: 13113.1885 - val_loss: 468931040.0000 - val_mae: 13768.8125\n",
            "Epoch 166/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 362597408.0000 - mae: 13019.7256 - val_loss: 454748512.0000 - val_mae: 13645.9170\n",
            "Epoch 167/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 352491552.0000 - mae: 12913.5498 - val_loss: 439946560.0000 - val_mae: 13399.3760\n",
            "Epoch 168/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 341488384.0000 - mae: 12493.9570 - val_loss: 427270464.0000 - val_mae: 13087.7617\n",
            "Epoch 169/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 330956000.0000 - mae: 12370.0078 - val_loss: 414678464.0000 - val_mae: 12947.2227\n",
            "Epoch 170/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 322100992.0000 - mae: 12112.5771 - val_loss: 402636640.0000 - val_mae: 12710.6982\n",
            "Epoch 171/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 311699200.0000 - mae: 12002.1504 - val_loss: 390758016.0000 - val_mae: 12597.7920\n",
            "Epoch 172/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 302936768.0000 - mae: 11790.4258 - val_loss: 379522368.0000 - val_mae: 12389.0400\n",
            "Epoch 173/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 294250624.0000 - mae: 11716.3447 - val_loss: 366988352.0000 - val_mae: 12193.0107\n",
            "Epoch 174/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 283949408.0000 - mae: 11499.8945 - val_loss: 356064160.0000 - val_mae: 12027.5234\n",
            "Epoch 175/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 274170048.0000 - mae: 11421.0469 - val_loss: 339964736.0000 - val_mae: 11834.5703\n",
            "Epoch 176/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 263810432.0000 - mae: 10983.6895 - val_loss: 328890368.0000 - val_mae: 11455.4434\n",
            "Epoch 177/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 254530384.0000 - mae: 11007.2832 - val_loss: 317578688.0000 - val_mae: 11575.4336\n",
            "Epoch 178/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 246665488.0000 - mae: 10685.3594 - val_loss: 306784992.0000 - val_mae: 11120.4971\n",
            "Epoch 179/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 237733520.0000 - mae: 10494.0244 - val_loss: 296846944.0000 - val_mae: 10994.0098\n",
            "Epoch 180/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 229952192.0000 - mae: 10265.5879 - val_loss: 287623168.0000 - val_mae: 10708.4414\n",
            "Epoch 181/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 223096192.0000 - mae: 10237.4150 - val_loss: 277125760.0000 - val_mae: 10690.3477\n",
            "Epoch 182/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 215397232.0000 - mae: 9934.9932 - val_loss: 268765504.0000 - val_mae: 10392.0303\n",
            "Epoch 183/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 208003280.0000 - mae: 9881.1895 - val_loss: 259465056.0000 - val_mae: 10329.3945\n",
            "Epoch 184/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 200992752.0000 - mae: 9656.6650 - val_loss: 250313040.0000 - val_mae: 9996.0156\n",
            "Epoch 185/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 194250912.0000 - mae: 9463.0293 - val_loss: 241588880.0000 - val_mae: 9953.9590\n",
            "Epoch 186/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 187535424.0000 - mae: 9365.0312 - val_loss: 233424560.0000 - val_mae: 9776.3857\n",
            "Epoch 187/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 181484688.0000 - mae: 9102.1748 - val_loss: 226050704.0000 - val_mae: 9515.2998\n",
            "Epoch 188/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 174852176.0000 - mae: 9044.6230 - val_loss: 217880384.0000 - val_mae: 9441.2793\n",
            "Epoch 189/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 168883200.0000 - mae: 8864.2051 - val_loss: 209674816.0000 - val_mae: 9231.4043\n",
            "Epoch 190/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 162550256.0000 - mae: 8645.9072 - val_loss: 202280592.0000 - val_mae: 9028.8760\n",
            "Epoch 191/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 157089584.0000 - mae: 8570.7803 - val_loss: 194477424.0000 - val_mae: 8899.7832\n",
            "Epoch 192/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 150915104.0000 - mae: 8405.4414 - val_loss: 187578368.0000 - val_mae: 8762.1611\n",
            "Epoch 193/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 145451264.0000 - mae: 8231.6016 - val_loss: 180495968.0000 - val_mae: 8625.0576\n",
            "Epoch 194/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 139918352.0000 - mae: 8097.8838 - val_loss: 173481664.0000 - val_mae: 8419.6094\n",
            "Epoch 195/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 135080288.0000 - mae: 7859.2090 - val_loss: 167154992.0000 - val_mae: 8244.6533\n",
            "Epoch 196/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 129568464.0000 - mae: 7802.0601 - val_loss: 160631440.0000 - val_mae: 8148.5581\n",
            "Epoch 197/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 124634112.0000 - mae: 7637.9048 - val_loss: 153977056.0000 - val_mae: 7992.3496\n",
            "Epoch 198/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 119578872.0000 - mae: 7439.0391 - val_loss: 148071104.0000 - val_mae: 7758.7002\n",
            "Epoch 199/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 114908040.0000 - mae: 7328.5610 - val_loss: 141959008.0000 - val_mae: 7657.5991\n",
            "Epoch 200/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 110219992.0000 - mae: 7156.4590 - val_loss: 136710704.0000 - val_mae: 7463.2407\n",
            "Epoch 201/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 106109128.0000 - mae: 7047.9189 - val_loss: 130949776.0000 - val_mae: 7410.9004\n",
            "Epoch 202/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 101609304.0000 - mae: 6928.1064 - val_loss: 125621072.0000 - val_mae: 7139.2183\n",
            "Epoch 203/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 97641320.0000 - mae: 6712.2847 - val_loss: 120328544.0000 - val_mae: 6964.4722\n",
            "Epoch 204/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 93465272.0000 - mae: 6593.2480 - val_loss: 115199808.0000 - val_mae: 6875.5845\n",
            "Epoch 205/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 89542800.0000 - mae: 6491.5938 - val_loss: 110391928.0000 - val_mae: 6782.5576\n",
            "Epoch 206/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 85913296.0000 - mae: 6414.0820 - val_loss: 105344016.0000 - val_mae: 6623.2471\n",
            "Epoch 207/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 82074920.0000 - mae: 6161.7183 - val_loss: 101056784.0000 - val_mae: 6442.7354\n",
            "Epoch 208/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 78665768.0000 - mae: 6123.0854 - val_loss: 96558648.0000 - val_mae: 6341.4941\n",
            "Epoch 209/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 75271360.0000 - mae: 5921.7285 - val_loss: 92339528.0000 - val_mae: 6142.1357\n",
            "Epoch 210/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 72088016.0000 - mae: 5828.7598 - val_loss: 88312232.0000 - val_mae: 6027.3159\n",
            "Epoch 211/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 68987448.0000 - mae: 5668.7119 - val_loss: 84673944.0000 - val_mae: 5949.7012\n",
            "Epoch 212/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 66011620.0000 - mae: 5555.1753 - val_loss: 80877824.0000 - val_mae: 5789.5464\n",
            "Epoch 213/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 63015080.0000 - mae: 5445.5767 - val_loss: 77361776.0000 - val_mae: 5678.1216\n",
            "Epoch 214/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 60428460.0000 - mae: 5364.7588 - val_loss: 73642280.0000 - val_mae: 5554.0527\n",
            "Epoch 215/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 57571664.0000 - mae: 5187.3716 - val_loss: 70353784.0000 - val_mae: 5408.7817\n",
            "Epoch 216/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 54906384.0000 - mae: 5113.8018 - val_loss: 67066524.0000 - val_mae: 5344.3647\n",
            "Epoch 217/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 52425704.0000 - mae: 4986.8213 - val_loss: 63957764.0000 - val_mae: 5210.5234\n",
            "Epoch 218/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 49999508.0000 - mae: 4898.5239 - val_loss: 60737112.0000 - val_mae: 5014.5356\n",
            "Epoch 219/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 47582572.0000 - mae: 4736.2412 - val_loss: 57794404.0000 - val_mae: 4946.6938\n",
            "Epoch 220/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 45332128.0000 - mae: 4659.8770 - val_loss: 54888320.0000 - val_mae: 4868.6431\n",
            "Epoch 221/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 43103544.0000 - mae: 4549.3022 - val_loss: 52278056.0000 - val_mae: 4637.0117\n",
            "Epoch 222/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 41019812.0000 - mae: 4404.2520 - val_loss: 49996176.0000 - val_mae: 4571.4131\n",
            "Epoch 223/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 39224124.0000 - mae: 4346.3257 - val_loss: 47408472.0000 - val_mae: 4494.8257\n",
            "Epoch 224/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 37205796.0000 - mae: 4216.2495 - val_loss: 45177544.0000 - val_mae: 4388.3115\n",
            "Epoch 225/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 35072660.0000 - mae: 4168.1733 - val_loss: 41985856.0000 - val_mae: 4258.8228\n",
            "Epoch 226/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 33062682.0000 - mae: 3990.7053 - val_loss: 39758616.0000 - val_mae: 4077.4868\n",
            "Epoch 227/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 31369326.0000 - mae: 3870.4097 - val_loss: 37727900.0000 - val_mae: 4023.0249\n",
            "Epoch 228/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 29884206.0000 - mae: 3783.9387 - val_loss: 36001500.0000 - val_mae: 3905.3379\n",
            "Epoch 229/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 28345404.0000 - mae: 3731.7915 - val_loss: 34177748.0000 - val_mae: 3888.8835\n",
            "Epoch 230/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 27018442.0000 - mae: 3634.9868 - val_loss: 32281060.0000 - val_mae: 3718.6677\n",
            "Epoch 231/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 25688944.0000 - mae: 3540.0061 - val_loss: 30577762.0000 - val_mae: 3595.8257\n",
            "Epoch 232/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 24309500.0000 - mae: 3448.4023 - val_loss: 29019708.0000 - val_mae: 3533.9895\n",
            "Epoch 233/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 23145362.0000 - mae: 3343.5266 - val_loss: 27406346.0000 - val_mae: 3435.9180\n",
            "Epoch 234/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 21922994.0000 - mae: 3290.9492 - val_loss: 25993304.0000 - val_mae: 3384.5020\n",
            "Epoch 235/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 20827528.0000 - mae: 3186.9851 - val_loss: 24729084.0000 - val_mae: 3278.2642\n",
            "Epoch 236/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 19764880.0000 - mae: 3139.0095 - val_loss: 23403420.0000 - val_mae: 3231.8799\n",
            "Epoch 237/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 18847894.0000 - mae: 3092.3040 - val_loss: 22024178.0000 - val_mae: 3101.7786\n",
            "Epoch 238/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 17821454.0000 - mae: 2941.5847 - val_loss: 20840502.0000 - val_mae: 3034.8445\n",
            "Epoch 239/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 16861150.0000 - mae: 2907.3330 - val_loss: 19718480.0000 - val_mae: 2952.6956\n",
            "Epoch 240/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 15965374.0000 - mae: 2809.7744 - val_loss: 18804706.0000 - val_mae: 2888.7051\n",
            "Epoch 241/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 15232452.0000 - mae: 2782.6335 - val_loss: 17708378.0000 - val_mae: 2809.7488\n",
            "Epoch 242/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 14433157.0000 - mae: 2689.7654 - val_loss: 16715298.0000 - val_mae: 2735.9131\n",
            "Epoch 243/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 13645449.0000 - mae: 2635.2417 - val_loss: 15835815.0000 - val_mae: 2690.0435\n",
            "Epoch 244/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 12847097.0000 - mae: 2584.8789 - val_loss: 14600002.0000 - val_mae: 2585.8040\n",
            "Epoch 245/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 12034761.0000 - mae: 2473.9316 - val_loss: 13791175.0000 - val_mae: 2525.4841\n",
            "Epoch 246/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 11429978.0000 - mae: 2421.3308 - val_loss: 13110652.0000 - val_mae: 2501.1375\n",
            "Epoch 247/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 10951104.0000 - mae: 2380.5100 - val_loss: 12386961.0000 - val_mae: 2411.1946\n",
            "Epoch 248/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 10318537.0000 - mae: 2342.6689 - val_loss: 11650453.0000 - val_mae: 2351.4014\n",
            "Epoch 249/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9745537.0000 - mae: 2252.0322 - val_loss: 11041515.0000 - val_mae: 2298.7527\n",
            "Epoch 250/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 9279759.0000 - mae: 2227.0447 - val_loss: 10451795.0000 - val_mae: 2238.2944\n",
            "Epoch 251/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 8841045.0000 - mae: 2153.6118 - val_loss: 9863901.0000 - val_mae: 2194.2512\n",
            "Epoch 252/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 8400311.0000 - mae: 2134.3477 - val_loss: 9367148.0000 - val_mae: 2133.4412\n",
            "Epoch 253/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 7987507.0000 - mae: 2073.6724 - val_loss: 8839985.0000 - val_mae: 2096.0793\n",
            "Epoch 254/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 7640143.5000 - mae: 2024.7916 - val_loss: 8381097.0000 - val_mae: 2057.2178\n",
            "Epoch 255/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 7246305.0000 - mae: 1986.7179 - val_loss: 7983789.0000 - val_mae: 2015.8391\n",
            "Epoch 256/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 6963006.0000 - mae: 1971.8906 - val_loss: 7580799.0000 - val_mae: 1941.9092\n",
            "Epoch 257/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 6626071.0000 - mae: 1912.4972 - val_loss: 7198532.5000 - val_mae: 1939.6552\n",
            "Epoch 258/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 6315859.5000 - mae: 1883.9794 - val_loss: 6826957.0000 - val_mae: 1873.8655\n",
            "Epoch 259/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 6027053.0000 - mae: 1839.6880 - val_loss: 6497333.5000 - val_mae: 1851.8916\n",
            "Epoch 260/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 5778177.0000 - mae: 1812.2000 - val_loss: 6183756.5000 - val_mae: 1808.0176\n",
            "Epoch 261/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 5535279.0000 - mae: 1781.2271 - val_loss: 5907484.5000 - val_mae: 1784.5057\n",
            "Epoch 262/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 5304206.5000 - mae: 1755.7095 - val_loss: 5657966.5000 - val_mae: 1736.2904\n",
            "Epoch 263/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 5110806.0000 - mae: 1720.9089 - val_loss: 5376939.5000 - val_mae: 1714.3894\n",
            "Epoch 264/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4901243.0000 - mae: 1691.7861 - val_loss: 5132759.5000 - val_mae: 1681.8524\n",
            "Epoch 265/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4727233.5000 - mae: 1671.1643 - val_loss: 4906911.0000 - val_mae: 1648.1671\n",
            "Epoch 266/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4535778.0000 - mae: 1642.9451 - val_loss: 4719827.0000 - val_mae: 1629.6543\n",
            "Epoch 267/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4405747.0000 - mae: 1625.4576 - val_loss: 4521357.0000 - val_mae: 1598.7183\n",
            "Epoch 268/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4245863.0000 - mae: 1602.8768 - val_loss: 4348792.0000 - val_mae: 1575.2140\n",
            "Epoch 269/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4106892.7500 - mae: 1578.8240 - val_loss: 4190967.5000 - val_mae: 1555.7175\n",
            "Epoch 270/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3977705.7500 - mae: 1560.5043 - val_loss: 4039075.0000 - val_mae: 1536.2480\n",
            "Epoch 271/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3861227.0000 - mae: 1540.2455 - val_loss: 3893393.5000 - val_mae: 1517.0945\n",
            "Epoch 272/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3755337.5000 - mae: 1526.6361 - val_loss: 3763327.2500 - val_mae: 1499.1075\n",
            "Epoch 273/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3648054.7500 - mae: 1508.1532 - val_loss: 3638479.5000 - val_mae: 1478.8539\n",
            "Epoch 274/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3546675.5000 - mae: 1491.5341 - val_loss: 3535907.5000 - val_mae: 1466.6523\n",
            "Epoch 275/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3460584.5000 - mae: 1480.8772 - val_loss: 3420594.0000 - val_mae: 1444.4365\n",
            "Epoch 276/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3385624.5000 - mae: 1463.8453 - val_loss: 3329227.7500 - val_mae: 1430.4988\n",
            "Epoch 277/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3303539.2500 - mae: 1456.0981 - val_loss: 3235762.7500 - val_mae: 1418.0031\n",
            "Epoch 278/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3235427.0000 - mae: 1437.0414 - val_loss: 3157097.5000 - val_mae: 1404.8207\n",
            "Epoch 279/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3215678.7500 - mae: 1440.0530 - val_loss: 3091137.5000 - val_mae: 1393.1002\n",
            "Epoch 280/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3116060.2500 - mae: 1423.9390 - val_loss: 3018228.7500 - val_mae: 1382.0554\n",
            "Epoch 281/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3058490.7500 - mae: 1407.1095 - val_loss: 2964876.0000 - val_mae: 1377.3732\n",
            "Epoch 282/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3001826.2500 - mae: 1399.4501 - val_loss: 2897026.2500 - val_mae: 1358.2339\n",
            "Epoch 283/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2961082.7500 - mae: 1387.6035 - val_loss: 2854421.7500 - val_mae: 1359.2303\n",
            "Epoch 284/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2918877.0000 - mae: 1381.0022 - val_loss: 2795192.0000 - val_mae: 1343.6313\n",
            "Epoch 285/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2878717.0000 - mae: 1378.0779 - val_loss: 2760559.0000 - val_mae: 1331.8445\n",
            "Epoch 286/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2847535.7500 - mae: 1369.4873 - val_loss: 2710474.2500 - val_mae: 1326.3441\n",
            "Epoch 287/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2819924.5000 - mae: 1359.8809 - val_loss: 2685078.2500 - val_mae: 1329.4337\n",
            "Epoch 288/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2784778.5000 - mae: 1360.6089 - val_loss: 2643314.7500 - val_mae: 1313.5028\n",
            "Epoch 289/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2752679.0000 - mae: 1350.2255 - val_loss: 2615857.0000 - val_mae: 1313.2606\n",
            "Epoch 290/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2733178.2500 - mae: 1347.1387 - val_loss: 2592136.5000 - val_mae: 1309.9908\n",
            "Epoch 291/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2707010.2500 - mae: 1344.2644 - val_loss: 2571868.2500 - val_mae: 1298.5773\n",
            "Epoch 292/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2697733.2500 - mae: 1337.6249 - val_loss: 2556405.7500 - val_mae: 1304.5424\n",
            "Epoch 293/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2661845.5000 - mae: 1332.0790 - val_loss: 2521614.7500 - val_mae: 1289.4233\n",
            "Epoch 294/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2651448.7500 - mae: 1331.4885 - val_loss: 2497117.7500 - val_mae: 1287.0867\n",
            "Epoch 295/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2620825.2500 - mae: 1322.6334 - val_loss: 2481144.0000 - val_mae: 1282.5154\n",
            "Epoch 296/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2610501.5000 - mae: 1321.5499 - val_loss: 2464826.0000 - val_mae: 1279.0010\n",
            "Epoch 297/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2600035.2500 - mae: 1319.2017 - val_loss: 2452347.7500 - val_mae: 1275.0885\n",
            "Epoch 298/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2596758.2500 - mae: 1318.8815 - val_loss: 2460634.5000 - val_mae: 1273.1178\n",
            "Epoch 299/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2580817.0000 - mae: 1310.2720 - val_loss: 2424173.5000 - val_mae: 1271.7501\n",
            "Epoch 300/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2550731.5000 - mae: 1305.9279 - val_loss: 2416493.2500 - val_mae: 1265.9652\n",
            "Epoch 301/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2552784.2500 - mae: 1307.4214 - val_loss: 2415607.7500 - val_mae: 1264.2131\n",
            "Epoch 302/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2545455.2500 - mae: 1300.2924 - val_loss: 2396320.7500 - val_mae: 1265.2900\n",
            "Epoch 303/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2524042.2500 - mae: 1300.7976 - val_loss: 2388142.2500 - val_mae: 1258.2883\n",
            "Epoch 304/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2526491.2500 - mae: 1297.4242 - val_loss: 2373781.2500 - val_mae: 1258.7726\n",
            "Epoch 305/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2505183.5000 - mae: 1295.5654 - val_loss: 2371141.5000 - val_mae: 1252.8193\n",
            "Epoch 306/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2507705.5000 - mae: 1292.9061 - val_loss: 2355313.7500 - val_mae: 1253.2727\n",
            "Epoch 307/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2493106.2500 - mae: 1291.9493 - val_loss: 2349193.2500 - val_mae: 1252.2128\n",
            "Epoch 308/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2482396.0000 - mae: 1293.4214 - val_loss: 2373087.0000 - val_mae: 1251.3286\n",
            "Epoch 309/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2508087.0000 - mae: 1294.5210 - val_loss: 2334939.0000 - val_mae: 1248.9684\n",
            "Epoch 310/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2480803.7500 - mae: 1290.3269 - val_loss: 2351719.2500 - val_mae: 1247.1200\n",
            "Epoch 311/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2479936.2500 - mae: 1289.6001 - val_loss: 2321633.2500 - val_mae: 1244.4985\n",
            "Epoch 312/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2465300.0000 - mae: 1286.1830 - val_loss: 2317397.5000 - val_mae: 1242.7534\n",
            "Epoch 313/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2475929.5000 - mae: 1285.7446 - val_loss: 2312212.7500 - val_mae: 1241.3025\n",
            "Epoch 314/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2457402.5000 - mae: 1278.1731 - val_loss: 2328974.7500 - val_mae: 1249.0103\n",
            "Epoch 315/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2503462.2500 - mae: 1299.1973 - val_loss: 2301673.2500 - val_mae: 1239.4254\n",
            "Epoch 316/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2473728.5000 - mae: 1288.9159 - val_loss: 2307596.5000 - val_mae: 1238.5140\n",
            "Epoch 317/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2428727.2500 - mae: 1273.9910 - val_loss: 2305106.7500 - val_mae: 1242.7783\n",
            "Epoch 318/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2447508.5000 - mae: 1280.7825 - val_loss: 2309974.7500 - val_mae: 1237.0844\n",
            "Epoch 319/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2431054.0000 - mae: 1276.7504 - val_loss: 2288162.0000 - val_mae: 1235.7958\n",
            "Epoch 320/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2429756.0000 - mae: 1276.0956 - val_loss: 2284546.7500 - val_mae: 1234.7472\n",
            "Epoch 321/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2429702.5000 - mae: 1273.6814 - val_loss: 2282431.5000 - val_mae: 1236.4504\n",
            "Epoch 322/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2422576.5000 - mae: 1271.9493 - val_loss: 2318132.0000 - val_mae: 1246.5950\n",
            "Epoch 323/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2478075.5000 - mae: 1293.5962 - val_loss: 2349579.0000 - val_mae: 1257.5255\n",
            "Epoch 324/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2412160.2500 - mae: 1267.4261 - val_loss: 2288167.0000 - val_mae: 1231.6487\n",
            "Epoch 325/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 2402591.0000 - mae: 1269.5994 - val_loss: 2281787.0000 - val_mae: 1230.1863\n",
            "Epoch 326/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2411983.2500 - mae: 1268.0967 - val_loss: 2253680.5000 - val_mae: 1227.7848\n",
            "Epoch 327/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2384233.5000 - mae: 1265.9087 - val_loss: 2280180.2500 - val_mae: 1229.6833\n",
            "Epoch 328/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2398066.7500 - mae: 1265.7208 - val_loss: 2243899.7500 - val_mae: 1226.1089\n",
            "Epoch 329/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2375938.2500 - mae: 1260.4752 - val_loss: 2254091.7500 - val_mae: 1224.2898\n",
            "Epoch 330/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2372048.2500 - mae: 1260.0426 - val_loss: 2247612.7500 - val_mae: 1222.0708\n",
            "Epoch 331/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2373977.5000 - mae: 1260.9747 - val_loss: 2234538.5000 - val_mae: 1223.1875\n",
            "Epoch 332/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2360507.2500 - mae: 1258.1548 - val_loss: 2226550.7500 - val_mae: 1219.2948\n",
            "Epoch 333/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2350062.5000 - mae: 1252.3373 - val_loss: 2224034.7500 - val_mae: 1219.3629\n",
            "Epoch 334/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2360712.5000 - mae: 1253.9790 - val_loss: 2217666.2500 - val_mae: 1218.3885\n",
            "Epoch 335/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2352162.5000 - mae: 1252.4011 - val_loss: 2242466.7500 - val_mae: 1218.0760\n",
            "Epoch 336/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2346498.5000 - mae: 1250.1881 - val_loss: 2222806.7500 - val_mae: 1219.0526\n",
            "Epoch 337/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2371761.2500 - mae: 1260.5044 - val_loss: 2218372.0000 - val_mae: 1217.8422\n",
            "Epoch 338/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2343736.7500 - mae: 1253.2245 - val_loss: 2219300.0000 - val_mae: 1218.4802\n",
            "Epoch 339/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2331451.5000 - mae: 1247.4916 - val_loss: 2192082.2500 - val_mae: 1210.5703\n",
            "Epoch 340/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2344372.7500 - mae: 1252.5597 - val_loss: 2193620.5000 - val_mae: 1208.8026\n",
            "Epoch 341/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2314168.0000 - mae: 1244.5574 - val_loss: 2209699.0000 - val_mae: 1209.6451\n",
            "Epoch 342/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2313344.7500 - mae: 1241.6580 - val_loss: 2187881.2500 - val_mae: 1209.4037\n",
            "Epoch 343/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2312051.5000 - mae: 1240.3466 - val_loss: 2172608.7500 - val_mae: 1204.9886\n",
            "Epoch 344/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2301090.5000 - mae: 1240.2021 - val_loss: 2182567.0000 - val_mae: 1207.9937\n",
            "Epoch 345/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2326898.0000 - mae: 1247.7034 - val_loss: 2174888.7500 - val_mae: 1205.5909\n",
            "Epoch 346/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2306370.5000 - mae: 1241.0779 - val_loss: 2157728.7500 - val_mae: 1201.3374\n",
            "Epoch 347/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2284956.0000 - mae: 1235.1289 - val_loss: 2159417.2500 - val_mae: 1201.3231\n",
            "Epoch 348/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2273957.0000 - mae: 1234.2124 - val_loss: 2171037.7500 - val_mae: 1199.4490\n",
            "Epoch 349/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2292577.2500 - mae: 1236.0901 - val_loss: 2157209.5000 - val_mae: 1197.1389\n",
            "Epoch 350/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2285960.5000 - mae: 1235.1367 - val_loss: 2161878.2500 - val_mae: 1196.4990\n",
            "Epoch 351/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2299730.5000 - mae: 1238.5117 - val_loss: 2148803.7500 - val_mae: 1194.6180\n",
            "Epoch 352/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 2286068.2500 - mae: 1234.5653 - val_loss: 2142263.2500 - val_mae: 1192.8318\n",
            "Epoch 353/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2268779.0000 - mae: 1229.9558 - val_loss: 2138313.0000 - val_mae: 1190.9263\n",
            "Epoch 354/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2340313.5000 - mae: 1250.2518 - val_loss: 2121731.0000 - val_mae: 1187.9309\n",
            "Epoch 355/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2256621.0000 - mae: 1229.2574 - val_loss: 2107805.2500 - val_mae: 1186.5844\n",
            "Epoch 356/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2226363.5000 - mae: 1218.3003 - val_loss: 2109719.5000 - val_mae: 1187.5115\n",
            "Epoch 357/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2225744.5000 - mae: 1218.9091 - val_loss: 2112117.7500 - val_mae: 1188.2140\n",
            "Epoch 358/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2234568.7500 - mae: 1224.9714 - val_loss: 2122485.7500 - val_mae: 1191.7515\n",
            "Epoch 359/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 2223235.0000 - mae: 1219.3885 - val_loss: 2105056.5000 - val_mae: 1186.5420\n",
            "Epoch 360/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 2205477.7500 - mae: 1215.2795 - val_loss: 2102171.7500 - val_mae: 1179.4180\n",
            "Epoch 361/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2201179.0000 - mae: 1213.9225 - val_loss: 2074429.2500 - val_mae: 1178.1500\n",
            "Epoch 362/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 2202528.0000 - mae: 1213.3767 - val_loss: 2068685.2500 - val_mae: 1176.2284\n",
            "Epoch 363/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 2191518.2500 - mae: 1209.7727 - val_loss: 2064071.0000 - val_mae: 1174.9779\n",
            "Epoch 364/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2194594.2500 - mae: 1211.9194 - val_loss: 2061501.8750 - val_mae: 1174.7333\n",
            "Epoch 365/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2181123.5000 - mae: 1205.9954 - val_loss: 2065434.1250 - val_mae: 1175.1025\n",
            "Epoch 366/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2200947.0000 - mae: 1214.7292 - val_loss: 2053770.3750 - val_mae: 1171.9857\n",
            "Epoch 367/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 2185722.7500 - mae: 1210.5867 - val_loss: 2039840.2500 - val_mae: 1168.1609\n",
            "Epoch 368/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2177638.7500 - mae: 1208.8306 - val_loss: 2039319.0000 - val_mae: 1167.1045\n",
            "Epoch 369/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2159811.0000 - mae: 1201.4424 - val_loss: 2036667.3750 - val_mae: 1164.8740\n",
            "Epoch 370/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2145763.7500 - mae: 1197.8179 - val_loss: 2024544.1250 - val_mae: 1161.4377\n",
            "Epoch 371/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2139885.7500 - mae: 1196.7493 - val_loss: 2042233.2500 - val_mae: 1168.8269\n",
            "Epoch 372/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2135172.2500 - mae: 1194.2483 - val_loss: 2007972.8750 - val_mae: 1158.6683\n",
            "Epoch 373/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2126668.5000 - mae: 1191.4467 - val_loss: 2005708.8750 - val_mae: 1155.5024\n",
            "Epoch 374/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2112762.7500 - mae: 1188.9370 - val_loss: 2033760.2500 - val_mae: 1157.8115\n",
            "Epoch 375/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2114812.5000 - mae: 1185.7156 - val_loss: 2008889.6250 - val_mae: 1158.8793\n",
            "Epoch 376/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2123490.5000 - mae: 1188.0851 - val_loss: 2000068.5000 - val_mae: 1156.4120\n",
            "Epoch 377/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2100099.2500 - mae: 1184.4229 - val_loss: 1978081.7500 - val_mae: 1149.3965\n",
            "Epoch 378/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2109843.5000 - mae: 1189.3094 - val_loss: 2020215.0000 - val_mae: 1154.2770\n",
            "Epoch 379/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2107167.2500 - mae: 1190.8906 - val_loss: 2005160.5000 - val_mae: 1149.3578\n",
            "Epoch 380/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2084254.3750 - mae: 1179.8282 - val_loss: 1975943.5000 - val_mae: 1142.7457\n",
            "Epoch 381/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2068583.6250 - mae: 1176.3840 - val_loss: 1968338.6250 - val_mae: 1141.3375\n",
            "Epoch 382/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2085974.3750 - mae: 1179.3832 - val_loss: 1952287.7500 - val_mae: 1138.2562\n",
            "Epoch 383/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2051973.8750 - mae: 1172.2694 - val_loss: 1935214.0000 - val_mae: 1136.7412\n",
            "Epoch 384/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2045437.6250 - mae: 1170.0273 - val_loss: 1936229.0000 - val_mae: 1137.4706\n",
            "Epoch 385/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2043265.0000 - mae: 1168.2059 - val_loss: 1936836.0000 - val_mae: 1133.1134\n",
            "Epoch 386/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2033902.6250 - mae: 1165.4886 - val_loss: 1915544.3750 - val_mae: 1131.5276\n",
            "Epoch 387/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2026836.7500 - mae: 1163.1436 - val_loss: 1907881.2500 - val_mae: 1129.0750\n",
            "Epoch 388/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2019701.7500 - mae: 1162.0583 - val_loss: 1954026.0000 - val_mae: 1132.2429\n",
            "Epoch 389/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2022814.1250 - mae: 1162.7557 - val_loss: 1895183.0000 - val_mae: 1122.8656\n",
            "Epoch 390/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2010643.8750 - mae: 1155.8451 - val_loss: 1889842.7500 - val_mae: 1124.1184\n",
            "Epoch 391/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2017245.1250 - mae: 1163.8834 - val_loss: 1881634.2500 - val_mae: 1121.3976\n",
            "Epoch 392/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2007146.1250 - mae: 1158.0957 - val_loss: 1876204.8750 - val_mae: 1117.4645\n",
            "Epoch 393/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1982104.5000 - mae: 1150.4668 - val_loss: 1877975.8750 - val_mae: 1120.1354\n",
            "Epoch 394/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1983737.1250 - mae: 1155.0270 - val_loss: 1934671.0000 - val_mae: 1140.6489\n",
            "Epoch 395/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2015766.6250 - mae: 1160.1104 - val_loss: 1864980.0000 - val_mae: 1116.6219\n",
            "Epoch 396/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1960999.5000 - mae: 1143.3453 - val_loss: 1870113.3750 - val_mae: 1118.6295\n",
            "Epoch 397/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1971433.2500 - mae: 1149.2306 - val_loss: 1837536.8750 - val_mae: 1109.2866\n",
            "Epoch 398/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1939819.0000 - mae: 1138.9071 - val_loss: 1830765.5000 - val_mae: 1106.9030\n",
            "Epoch 399/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1958141.8750 - mae: 1143.8325 - val_loss: 1825294.3750 - val_mae: 1105.0355\n",
            "Epoch 400/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1931052.1250 - mae: 1137.2704 - val_loss: 1823029.1250 - val_mae: 1104.4629\n",
            "Epoch 401/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1926034.8750 - mae: 1136.5372 - val_loss: 1844633.8750 - val_mae: 1111.5939\n",
            "Epoch 402/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1920791.5000 - mae: 1130.9561 - val_loss: 1830735.5000 - val_mae: 1099.2772\n",
            "Epoch 403/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1958046.6250 - mae: 1144.6788 - val_loss: 1787443.3750 - val_mae: 1091.4944\n",
            "Epoch 404/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1900887.0000 - mae: 1126.0050 - val_loss: 1789139.8750 - val_mae: 1093.2747\n",
            "Epoch 405/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1900578.2500 - mae: 1128.8594 - val_loss: 1772730.8750 - val_mae: 1088.0018\n",
            "Epoch 406/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1873854.1250 - mae: 1117.1138 - val_loss: 1765856.3750 - val_mae: 1085.2144\n",
            "Epoch 407/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1863907.5000 - mae: 1115.8885 - val_loss: 1756753.1250 - val_mae: 1083.6273\n",
            "Epoch 408/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1848506.6250 - mae: 1111.8088 - val_loss: 1786900.2500 - val_mae: 1085.0281\n",
            "Epoch 409/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1874217.3750 - mae: 1111.7373 - val_loss: 1745739.5000 - val_mae: 1078.8536\n",
            "Epoch 410/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1848522.2500 - mae: 1112.5223 - val_loss: 1733488.2500 - val_mae: 1076.4799\n",
            "Epoch 411/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1853310.7500 - mae: 1111.8506 - val_loss: 1751814.0000 - val_mae: 1078.2075\n",
            "Epoch 412/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1840730.2500 - mae: 1113.4305 - val_loss: 1719572.8750 - val_mae: 1073.6702\n",
            "Epoch 413/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1837037.5000 - mae: 1109.7760 - val_loss: 1715371.2500 - val_mae: 1070.5452\n",
            "Epoch 414/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1816101.8750 - mae: 1101.1588 - val_loss: 1704880.5000 - val_mae: 1067.5375\n",
            "Epoch 415/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1815346.6250 - mae: 1100.4531 - val_loss: 1697336.5000 - val_mae: 1064.7310\n",
            "Epoch 416/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1815235.5000 - mae: 1100.8801 - val_loss: 1775507.2500 - val_mae: 1094.0076\n",
            "Epoch 417/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1853206.0000 - mae: 1107.9637 - val_loss: 1682102.6250 - val_mae: 1060.2974\n",
            "Epoch 418/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1833864.8750 - mae: 1106.6495 - val_loss: 1775144.2500 - val_mae: 1076.8362\n",
            "Epoch 419/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1830943.2500 - mae: 1109.4900 - val_loss: 1690706.6250 - val_mae: 1064.0433\n",
            "Epoch 420/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1786793.1250 - mae: 1092.2699 - val_loss: 1648926.6250 - val_mae: 1049.9838\n",
            "Epoch 421/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1772905.3750 - mae: 1086.8434 - val_loss: 1644728.7500 - val_mae: 1048.3739\n",
            "Epoch 422/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1748651.8750 - mae: 1078.2852 - val_loss: 1641008.2500 - val_mae: 1045.8042\n",
            "Epoch 423/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1719068.2500 - mae: 1072.6107 - val_loss: 1701857.6250 - val_mae: 1055.2721\n",
            "Epoch 424/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1745800.0000 - mae: 1077.5568 - val_loss: 1614716.7500 - val_mae: 1039.2985\n",
            "Epoch 425/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1709918.0000 - mae: 1069.3456 - val_loss: 1603954.6250 - val_mae: 1035.8453\n",
            "Epoch 426/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1701874.1250 - mae: 1066.4774 - val_loss: 1605137.0000 - val_mae: 1035.5760\n",
            "Epoch 427/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1699318.6250 - mae: 1063.1332 - val_loss: 1586917.8750 - val_mae: 1030.3552\n",
            "Epoch 428/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1719186.7500 - mae: 1069.2513 - val_loss: 1582035.0000 - val_mae: 1027.9706\n",
            "Epoch 429/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1686625.5000 - mae: 1060.6024 - val_loss: 1622433.6250 - val_mae: 1034.3398\n",
            "Epoch 430/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1677505.7500 - mae: 1060.7744 - val_loss: 1566917.1250 - val_mae: 1020.9783\n",
            "Epoch 431/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1641902.5000 - mae: 1049.3698 - val_loss: 1553172.6250 - val_mae: 1019.7120\n",
            "Epoch 432/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1651616.1250 - mae: 1052.4319 - val_loss: 1552819.3750 - val_mae: 1016.0466\n",
            "Epoch 433/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1629189.3750 - mae: 1044.4315 - val_loss: 1540474.3750 - val_mae: 1015.6570\n",
            "Epoch 434/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1634550.6250 - mae: 1048.6477 - val_loss: 1623658.6250 - val_mae: 1046.3650\n",
            "Epoch 435/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1634812.1250 - mae: 1047.7159 - val_loss: 1587466.8750 - val_mae: 1018.8192\n",
            "Epoch 436/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1639843.1250 - mae: 1040.3885 - val_loss: 1510119.5000 - val_mae: 1004.3611\n",
            "Epoch 437/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1625653.1250 - mae: 1043.2340 - val_loss: 1495285.3750 - val_mae: 998.2424\n",
            "Epoch 438/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1645574.2500 - mae: 1051.5948 - val_loss: 1494647.0000 - val_mae: 996.0715\n",
            "Epoch 439/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1584862.7500 - mae: 1033.5304 - val_loss: 1559938.0000 - val_mae: 1025.5151\n",
            "Epoch 440/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1609846.1250 - mae: 1039.5742 - val_loss: 1483869.0000 - val_mae: 993.1859\n",
            "Epoch 441/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1553962.5000 - mae: 1017.6383 - val_loss: 1457388.7500 - val_mae: 987.1636\n",
            "Epoch 442/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1590586.8750 - mae: 1029.1819 - val_loss: 1457511.5000 - val_mae: 982.0912\n",
            "Epoch 443/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1572033.1250 - mae: 1021.6261 - val_loss: 1524169.0000 - val_mae: 1013.7852\n",
            "Epoch 444/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1578375.2500 - mae: 1025.7645 - val_loss: 1467337.3750 - val_mae: 991.8546\n",
            "Epoch 445/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1517053.1250 - mae: 1010.8890 - val_loss: 1418353.5000 - val_mae: 974.6009\n",
            "Epoch 446/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1510111.0000 - mae: 1004.3887 - val_loss: 1422731.6250 - val_mae: 971.2202\n",
            "Epoch 447/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1492250.3750 - mae: 996.7296 - val_loss: 1398855.0000 - val_mae: 966.9457\n",
            "Epoch 448/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1490744.1250 - mae: 997.9002 - val_loss: 1390678.6250 - val_mae: 964.4390\n",
            "Epoch 449/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1477684.2500 - mae: 996.3358 - val_loss: 1382360.3750 - val_mae: 960.7955\n",
            "Epoch 450/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1481786.2500 - mae: 996.7134 - val_loss: 1398533.6250 - val_mae: 961.0513\n",
            "Epoch 451/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1481166.0000 - mae: 998.9265 - val_loss: 1373227.7500 - val_mae: 958.1805\n",
            "Epoch 452/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1450815.2500 - mae: 984.3076 - val_loss: 1372438.0000 - val_mae: 952.2332\n",
            "Epoch 453/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1430414.0000 - mae: 975.8851 - val_loss: 1357968.3750 - val_mae: 949.3325\n",
            "Epoch 454/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1483814.8750 - mae: 999.6085 - val_loss: 1447215.3750 - val_mae: 988.8270\n",
            "Epoch 455/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1410090.2500 - mae: 970.5518 - val_loss: 1322647.8750 - val_mae: 940.5058\n",
            "Epoch 456/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1415898.8750 - mae: 970.6606 - val_loss: 1311246.6250 - val_mae: 935.5927\n",
            "Epoch 457/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1387177.2500 - mae: 961.6892 - val_loss: 1377235.2500 - val_mae: 947.5480\n",
            "Epoch 458/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1404275.8750 - mae: 968.4041 - val_loss: 1404096.0000 - val_mae: 971.6536\n",
            "Epoch 459/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1394179.3750 - mae: 962.3314 - val_loss: 1399651.0000 - val_mae: 953.2439\n",
            "Epoch 460/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1429878.1250 - mae: 967.8528 - val_loss: 1381785.3750 - val_mae: 966.2048\n",
            "Epoch 461/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1388964.6250 - mae: 962.5889 - val_loss: 1376079.7500 - val_mae: 948.6265\n",
            "Epoch 462/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1371868.3750 - mae: 957.6163 - val_loss: 1267060.2500 - val_mae: 920.7497\n",
            "Epoch 463/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1366052.0000 - mae: 960.5848 - val_loss: 1284835.2500 - val_mae: 929.4291\n",
            "Epoch 464/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1341290.7500 - mae: 947.4792 - val_loss: 1261573.8750 - val_mae: 911.5978\n",
            "Epoch 465/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1328390.6250 - mae: 943.5372 - val_loss: 1243055.0000 - val_mae: 905.5363\n",
            "Epoch 466/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1336287.7500 - mae: 944.4850 - val_loss: 1227211.7500 - val_mae: 900.6055\n",
            "Epoch 467/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1314892.1250 - mae: 933.9561 - val_loss: 1331287.7500 - val_mae: 947.8320\n",
            "Epoch 468/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1306699.3750 - mae: 934.8268 - val_loss: 1254169.8750 - val_mae: 905.2787\n",
            "Epoch 469/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1265340.1250 - mae: 914.1191 - val_loss: 1197676.2500 - val_mae: 887.9462\n",
            "Epoch 470/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1257865.3750 - mae: 919.4798 - val_loss: 1168336.6250 - val_mae: 882.8372\n",
            "Epoch 471/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1231235.5000 - mae: 905.9642 - val_loss: 1164123.5000 - val_mae: 878.1948\n",
            "Epoch 472/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1240771.1250 - mae: 913.3955 - val_loss: 1233370.5000 - val_mae: 912.5886\n",
            "Epoch 473/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1286690.0000 - mae: 925.7803 - val_loss: 1225894.7500 - val_mae: 908.2614\n",
            "Epoch 474/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1212575.8750 - mae: 901.5417 - val_loss: 1151876.7500 - val_mae: 870.5887\n",
            "Epoch 475/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1203562.3750 - mae: 897.4609 - val_loss: 1136125.5000 - val_mae: 866.3769\n",
            "Epoch 476/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1190655.3750 - mae: 891.8845 - val_loss: 1115969.5000 - val_mae: 863.5701\n",
            "Epoch 477/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1186567.8750 - mae: 893.3405 - val_loss: 1104976.2500 - val_mae: 859.2069\n",
            "Epoch 478/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1155415.1250 - mae: 878.6851 - val_loss: 1085461.7500 - val_mae: 849.9937\n",
            "Epoch 479/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1193460.3750 - mae: 891.2108 - val_loss: 1078159.7500 - val_mae: 846.7273\n",
            "Epoch 480/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1175994.8750 - mae: 885.4225 - val_loss: 1216961.5000 - val_mae: 906.8972\n",
            "Epoch 481/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1135641.3750 - mae: 871.2637 - val_loss: 1104630.8750 - val_mae: 850.2906\n",
            "Epoch 482/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1233862.0000 - mae: 908.8833 - val_loss: 1090227.1250 - val_mae: 844.5427\n",
            "Epoch 483/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1204634.2500 - mae: 899.9821 - val_loss: 1111921.2500 - val_mae: 849.3965\n",
            "Epoch 484/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1130073.3750 - mae: 868.2686 - val_loss: 1032137.8125 - val_mae: 830.5467\n",
            "Epoch 485/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1104026.7500 - mae: 857.9113 - val_loss: 1020491.0000 - val_mae: 823.0130\n",
            "Epoch 486/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1114863.3750 - mae: 857.6973 - val_loss: 1065505.5000 - val_mae: 833.6328\n",
            "Epoch 487/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1092789.5000 - mae: 856.5074 - val_loss: 1089864.5000 - val_mae: 842.1151\n",
            "Epoch 488/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1070299.0000 - mae: 842.5700 - val_loss: 987064.5625 - val_mae: 812.2152\n",
            "Epoch 489/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1054720.7500 - mae: 841.7110 - val_loss: 984254.7500 - val_mae: 807.2003\n",
            "Epoch 490/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1042273.5625 - mae: 833.1127 - val_loss: 973408.6250 - val_mae: 806.8661\n",
            "Epoch 491/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1020850.5000 - mae: 827.4202 - val_loss: 951897.8125 - val_mae: 798.6603\n",
            "Epoch 492/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1013774.4375 - mae: 825.1207 - val_loss: 940001.3750 - val_mae: 793.0618\n",
            "Epoch 493/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1067943.1250 - mae: 847.9715 - val_loss: 968668.1250 - val_mae: 793.9514\n",
            "Epoch 494/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1013644.4375 - mae: 824.2618 - val_loss: 1011432.5625 - val_mae: 810.6312\n",
            "Epoch 495/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 996528.6875 - mae: 816.1115 - val_loss: 907563.5625 - val_mae: 776.8120\n",
            "Epoch 496/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 992772.0000 - mae: 816.3831 - val_loss: 922929.5000 - val_mae: 778.3560\n",
            "Epoch 497/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 966929.3125 - mae: 805.3666 - val_loss: 900043.5625 - val_mae: 770.4492\n",
            "Epoch 498/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 952802.1875 - mae: 799.8967 - val_loss: 980752.5625 - val_mae: 798.5402\n",
            "Epoch 499/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1099634.3750 - mae: 850.9911 - val_loss: 988341.8125 - val_mae: 802.9996\n",
            "Epoch 500/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 977838.9375 - mae: 807.8624 - val_loss: 919844.0625 - val_mae: 771.8511\n",
            "Epoch 501/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 912276.5000 - mae: 780.2115 - val_loss: 857165.8125 - val_mae: 752.1497\n",
            "Epoch 502/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 976632.6875 - mae: 806.9641 - val_loss: 947754.5000 - val_mae: 783.5538\n",
            "Epoch 503/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 964316.8750 - mae: 799.1913 - val_loss: 840116.0625 - val_mae: 740.8679\n",
            "Epoch 504/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 911577.1250 - mae: 785.3638 - val_loss: 924474.6250 - val_mae: 789.8528\n",
            "Epoch 505/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 886145.1875 - mae: 768.5021 - val_loss: 806067.3125 - val_mae: 733.7980\n",
            "Epoch 506/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 859898.0625 - mae: 758.2156 - val_loss: 794276.9375 - val_mae: 729.3618\n",
            "Epoch 507/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 854333.5625 - mae: 754.4628 - val_loss: 938731.9375 - val_mae: 781.7255\n",
            "Epoch 508/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 885412.5625 - mae: 767.0001 - val_loss: 774879.6250 - val_mae: 716.9804\n",
            "Epoch 509/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 834661.1250 - mae: 745.0229 - val_loss: 805026.9375 - val_mae: 727.1904\n",
            "Epoch 510/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 851596.5000 - mae: 753.7602 - val_loss: 905483.5625 - val_mae: 784.7229\n",
            "Epoch 511/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 849913.1250 - mae: 754.1263 - val_loss: 744007.5000 - val_mae: 706.2153\n",
            "Epoch 512/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 843848.8125 - mae: 753.7545 - val_loss: 752662.1250 - val_mae: 703.0126\n",
            "Epoch 513/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 876764.7500 - mae: 766.6734 - val_loss: 801106.0000 - val_mae: 721.2500\n",
            "Epoch 514/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 802084.3125 - mae: 731.0172 - val_loss: 758510.3125 - val_mae: 715.1710\n",
            "Epoch 515/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 759396.0625 - mae: 713.1917 - val_loss: 702754.4375 - val_mae: 684.6886\n",
            "Epoch 516/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 767626.0625 - mae: 715.0400 - val_loss: 693446.4375 - val_mae: 680.3009\n",
            "Epoch 517/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 745463.8125 - mae: 704.5905 - val_loss: 687658.5625 - val_mae: 677.1206\n",
            "Epoch 518/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 726499.0000 - mae: 696.6921 - val_loss: 689808.2500 - val_mae: 672.9017\n",
            "Epoch 519/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 752816.6875 - mae: 709.2873 - val_loss: 896912.3750 - val_mae: 761.2310\n",
            "Epoch 520/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 730287.7500 - mae: 697.2498 - val_loss: 656928.0000 - val_mae: 659.4340\n",
            "Epoch 521/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 718756.3750 - mae: 691.8986 - val_loss: 706404.5625 - val_mae: 689.8255\n",
            "Epoch 522/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 742220.2500 - mae: 703.1945 - val_loss: 862610.0625 - val_mae: 773.2197\n",
            "Epoch 523/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 754783.6875 - mae: 714.5148 - val_loss: 674486.6250 - val_mae: 674.9174\n",
            "Epoch 524/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 737953.4375 - mae: 697.8820 - val_loss: 790056.4375 - val_mae: 717.2669\n",
            "Epoch 525/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 709672.8750 - mae: 689.0875 - val_loss: 683328.1250 - val_mae: 679.9620\n",
            "Epoch 526/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 668235.0000 - mae: 670.8865 - val_loss: 612339.8125 - val_mae: 635.5865\n",
            "Epoch 527/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 641981.7500 - mae: 658.3627 - val_loss: 622676.9375 - val_mae: 637.2396\n",
            "Epoch 528/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 666172.7500 - mae: 668.5897 - val_loss: 583928.3125 - val_mae: 623.4285\n",
            "Epoch 529/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 728048.6875 - mae: 693.9456 - val_loss: 571337.0625 - val_mae: 613.8551\n",
            "Epoch 530/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 732021.5000 - mae: 692.8560 - val_loss: 562185.7500 - val_mae: 612.5661\n",
            "Epoch 531/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 591778.1875 - mae: 630.3665 - val_loss: 698144.1250 - val_mae: 672.9990\n",
            "Epoch 532/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 707949.6250 - mae: 683.8538 - val_loss: 833839.0625 - val_mae: 765.0302\n",
            "Epoch 533/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 700363.0000 - mae: 681.5262 - val_loss: 650340.5000 - val_mae: 652.5211\n",
            "Epoch 534/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 633710.0625 - mae: 647.4720 - val_loss: 533187.5000 - val_mae: 597.2725\n",
            "Epoch 535/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 560270.0000 - mae: 610.9654 - val_loss: 540032.6250 - val_mae: 602.0950\n",
            "Epoch 536/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 548982.9375 - mae: 604.2437 - val_loss: 510167.0312 - val_mae: 584.1052\n",
            "Epoch 537/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 540909.8750 - mae: 605.0440 - val_loss: 514876.6875 - val_mae: 587.7850\n",
            "Epoch 538/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 600435.0000 - mae: 637.1643 - val_loss: 506272.2812 - val_mae: 575.2017\n",
            "Epoch 539/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 525177.7500 - mae: 590.6790 - val_loss: 519995.2188 - val_mae: 581.6416\n",
            "Epoch 540/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 511655.4688 - mae: 584.9238 - val_loss: 477695.5000 - val_mae: 563.2235\n",
            "Epoch 541/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 515735.5938 - mae: 582.0095 - val_loss: 464553.0312 - val_mae: 557.0369\n",
            "Epoch 542/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 519391.0312 - mae: 590.5556 - val_loss: 605547.9375 - val_mae: 629.8625\n",
            "Epoch 543/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 506049.1562 - mae: 581.2673 - val_loss: 529919.6250 - val_mae: 589.3785\n",
            "Epoch 544/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 496933.0312 - mae: 575.9412 - val_loss: 515612.2812 - val_mae: 592.0073\n",
            "Epoch 545/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 498086.5312 - mae: 578.4050 - val_loss: 443308.3438 - val_mae: 538.8539\n",
            "Epoch 546/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 477415.7812 - mae: 566.9440 - val_loss: 474363.6562 - val_mae: 565.6385\n",
            "Epoch 547/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 459515.3750 - mae: 552.7340 - val_loss: 411246.1562 - val_mae: 524.3004\n",
            "Epoch 548/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 446652.6875 - mae: 547.0866 - val_loss: 460051.1875 - val_mae: 545.8310\n",
            "Epoch 549/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 457174.4688 - mae: 554.2976 - val_loss: 467565.3438 - val_mae: 563.4981\n",
            "Epoch 550/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 433846.8125 - mae: 541.5715 - val_loss: 390435.5000 - val_mae: 510.2788\n",
            "Epoch 551/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 440293.5625 - mae: 543.6874 - val_loss: 380697.2812 - val_mae: 503.5777\n",
            "Epoch 552/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 413082.8125 - mae: 522.3254 - val_loss: 380601.4062 - val_mae: 504.7690\n",
            "Epoch 553/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 409577.7500 - mae: 522.5499 - val_loss: 405185.6250 - val_mae: 522.8641\n",
            "Epoch 554/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 396930.7812 - mae: 519.0704 - val_loss: 357467.1250 - val_mae: 489.0858\n",
            "Epoch 555/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 386916.8438 - mae: 509.4796 - val_loss: 370391.6562 - val_mae: 492.5938\n",
            "Epoch 556/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 381325.5312 - mae: 504.9837 - val_loss: 346579.1562 - val_mae: 481.4888\n",
            "Epoch 557/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 374941.0000 - mae: 503.8146 - val_loss: 344193.3125 - val_mae: 480.1732\n",
            "Epoch 558/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 381173.6875 - mae: 506.6861 - val_loss: 415206.0938 - val_mae: 532.8054\n",
            "Epoch 559/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 390696.9062 - mae: 511.0939 - val_loss: 322917.9688 - val_mae: 464.3844\n",
            "Epoch 560/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 351466.1875 - mae: 483.5925 - val_loss: 347708.3750 - val_mae: 474.7645\n",
            "Epoch 561/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 451863.8750 - mae: 544.8213 - val_loss: 361027.4062 - val_mae: 496.6079\n",
            "Epoch 562/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 384619.4062 - mae: 505.4577 - val_loss: 413424.2188 - val_mae: 535.9163\n",
            "Epoch 563/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 337522.3750 - mae: 475.0993 - val_loss: 403956.5625 - val_mae: 526.2982\n",
            "Epoch 564/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 371435.3125 - mae: 496.2400 - val_loss: 288901.6250 - val_mae: 436.6794\n",
            "Epoch 565/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 309542.8750 - mae: 455.4992 - val_loss: 279208.6250 - val_mae: 432.4701\n",
            "Epoch 566/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 300455.1250 - mae: 448.0688 - val_loss: 287206.1875 - val_mae: 432.1542\n",
            "Epoch 567/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 296719.6562 - mae: 444.8462 - val_loss: 277120.4375 - val_mae: 428.9711\n",
            "Epoch 568/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 309670.6875 - mae: 450.9160 - val_loss: 292366.9062 - val_mae: 436.4040\n",
            "Epoch 569/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 323105.6562 - mae: 460.1093 - val_loss: 269659.6250 - val_mae: 426.6707\n",
            "Epoch 570/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 319513.7812 - mae: 462.8597 - val_loss: 248483.7969 - val_mae: 408.5197\n",
            "Epoch 571/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 273111.5625 - mae: 430.0587 - val_loss: 251420.2500 - val_mae: 405.4801\n",
            "Epoch 572/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 262283.6250 - mae: 418.1702 - val_loss: 238754.1250 - val_mae: 395.6994\n",
            "Epoch 573/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 255906.5000 - mae: 416.8152 - val_loss: 271904.8750 - val_mae: 428.9025\n",
            "Epoch 574/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 263670.4688 - mae: 420.8835 - val_loss: 256687.7031 - val_mae: 418.5909\n",
            "Epoch 575/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 240895.1406 - mae: 403.2416 - val_loss: 230502.0781 - val_mae: 387.2700\n",
            "Epoch 576/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 255980.5312 - mae: 409.7574 - val_loss: 217279.8125 - val_mae: 377.3416\n",
            "Epoch 577/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 234262.3750 - mae: 395.5993 - val_loss: 226023.0312 - val_mae: 384.2841\n",
            "Epoch 578/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 233207.9688 - mae: 393.0885 - val_loss: 227174.8125 - val_mae: 390.2389\n",
            "Epoch 579/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 222716.1406 - mae: 387.7797 - val_loss: 250709.6719 - val_mae: 397.6252\n",
            "Epoch 580/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 222996.6875 - mae: 387.5966 - val_loss: 208263.0312 - val_mae: 373.5789\n",
            "Epoch 581/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 206846.2969 - mae: 372.6103 - val_loss: 184830.8750 - val_mae: 349.2930\n",
            "Epoch 582/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 211688.6562 - mae: 378.0867 - val_loss: 182629.6562 - val_mae: 349.6573\n",
            "Epoch 583/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 209440.3281 - mae: 370.6744 - val_loss: 174712.1875 - val_mae: 342.9101\n",
            "Epoch 584/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 190855.1719 - mae: 356.2399 - val_loss: 182727.7031 - val_mae: 344.2978\n",
            "Epoch 585/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 192684.6406 - mae: 359.8568 - val_loss: 186126.1875 - val_mae: 354.8248\n",
            "Epoch 586/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 200829.5469 - mae: 367.2789 - val_loss: 170389.3906 - val_mae: 338.1506\n",
            "Epoch 587/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 171593.6250 - mae: 340.5355 - val_loss: 154691.6406 - val_mae: 319.8933\n",
            "Epoch 588/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 184130.0625 - mae: 350.9066 - val_loss: 151295.1875 - val_mae: 318.3662\n",
            "Epoch 589/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 163727.4219 - mae: 329.0921 - val_loss: 180337.6094 - val_mae: 342.0966\n",
            "Epoch 590/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 166976.0938 - mae: 330.5541 - val_loss: 165056.3438 - val_mae: 334.4676\n",
            "Epoch 591/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 162776.5938 - mae: 331.9143 - val_loss: 296184.1250 - val_mae: 463.4185\n",
            "Epoch 592/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 189506.4531 - mae: 354.7277 - val_loss: 139529.7344 - val_mae: 306.6193\n",
            "Epoch 593/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 141670.8281 - mae: 308.6948 - val_loss: 138415.5000 - val_mae: 299.6019\n",
            "Epoch 594/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 149544.2344 - mae: 315.8682 - val_loss: 206573.8281 - val_mae: 366.5209\n",
            "Epoch 595/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 164677.0312 - mae: 328.6255 - val_loss: 129812.2656 - val_mae: 295.5739\n",
            "Epoch 596/1000\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 137557.2344 - mae: 302.6866 - val_loss: 192213.7344 - val_mae: 352.2964\n",
            "Epoch 597/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 157803.5000 - mae: 326.1992 - val_loss: 194625.8594 - val_mae: 368.0146\n",
            "Epoch 598/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 140005.5156 - mae: 305.2342 - val_loss: 113077.0547 - val_mae: 272.0137\n",
            "Epoch 599/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 125391.4922 - mae: 289.1736 - val_loss: 105853.4688 - val_mae: 266.6822\n",
            "Epoch 600/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 111708.0781 - mae: 273.5671 - val_loss: 102985.9297 - val_mae: 262.3409\n",
            "Epoch 601/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 122616.2578 - mae: 283.4657 - val_loss: 109868.7188 - val_mae: 269.3467\n",
            "Epoch 602/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 118367.1484 - mae: 282.2856 - val_loss: 96852.1406 - val_mae: 252.5444\n",
            "Epoch 603/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 103146.1875 - mae: 263.5826 - val_loss: 122299.1641 - val_mae: 287.4010\n",
            "Epoch 604/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 106839.9688 - mae: 268.1765 - val_loss: 107323.8750 - val_mae: 270.9367\n",
            "Epoch 605/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 132656.7969 - mae: 298.7356 - val_loss: 132053.2344 - val_mae: 291.8080\n",
            "Epoch 606/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 110333.6562 - mae: 269.4011 - val_loss: 83611.6875 - val_mae: 236.2523\n",
            "Epoch 607/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 100102.2891 - mae: 259.0009 - val_loss: 104326.0234 - val_mae: 264.6817\n",
            "Epoch 608/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 88811.5234 - mae: 241.0370 - val_loss: 78007.5391 - val_mae: 228.4233\n",
            "Epoch 609/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 97851.2266 - mae: 256.8060 - val_loss: 84745.5781 - val_mae: 233.5683\n",
            "Epoch 610/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 83097.6172 - mae: 235.2912 - val_loss: 73990.6562 - val_mae: 222.9696\n",
            "Epoch 611/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 82769.5547 - mae: 235.1560 - val_loss: 69077.4688 - val_mae: 215.6066\n",
            "Epoch 612/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 93684.3906 - mae: 249.3976 - val_loss: 86214.5703 - val_mae: 239.6146\n",
            "Epoch 613/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 86437.0781 - mae: 241.5192 - val_loss: 78322.1484 - val_mae: 221.3687\n",
            "Epoch 614/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 87393.5234 - mae: 238.3574 - val_loss: 106210.0391 - val_mae: 271.5832\n",
            "Epoch 615/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 76189.8750 - mae: 225.4736 - val_loss: 86745.9531 - val_mae: 248.4882\n",
            "Epoch 616/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 66896.8672 - mae: 213.5573 - val_loss: 57742.0703 - val_mae: 196.9437\n",
            "Epoch 617/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 70714.6719 - mae: 216.1496 - val_loss: 56522.4023 - val_mae: 192.8499\n",
            "Epoch 618/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 63721.3398 - mae: 205.9211 - val_loss: 59954.1211 - val_mae: 198.9003\n",
            "Epoch 619/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 60503.8125 - mae: 201.6818 - val_loss: 61846.2070 - val_mae: 204.8083\n",
            "Epoch 620/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 62508.2148 - mae: 203.0721 - val_loss: 48764.0938 - val_mae: 180.9279\n",
            "Epoch 621/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 62426.3086 - mae: 203.0879 - val_loss: 75668.1953 - val_mae: 231.5375\n",
            "Epoch 622/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 55436.7070 - mae: 192.8691 - val_loss: 51047.6992 - val_mae: 181.2505\n",
            "Epoch 623/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 50008.1445 - mae: 182.0502 - val_loss: 45053.5859 - val_mae: 173.8984\n",
            "Epoch 624/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 44908.4805 - mae: 173.4080 - val_loss: 45380.7148 - val_mae: 175.7455\n",
            "Epoch 625/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 45805.9688 - mae: 174.8238 - val_loss: 42313.6250 - val_mae: 165.6783\n",
            "Epoch 626/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 50138.9062 - mae: 182.6742 - val_loss: 49968.4062 - val_mae: 179.6040\n",
            "Epoch 627/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 41506.7227 - mae: 166.7701 - val_loss: 35491.0820 - val_mae: 154.2844\n",
            "Epoch 628/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 38273.5938 - mae: 160.7634 - val_loss: 36294.7578 - val_mae: 153.4830\n",
            "Epoch 629/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 37292.1328 - mae: 156.3674 - val_loss: 35959.3789 - val_mae: 157.5943\n",
            "Epoch 630/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 36364.5547 - mae: 155.4404 - val_loss: 39138.5977 - val_mae: 160.2799\n",
            "Epoch 631/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 35756.2852 - mae: 153.2556 - val_loss: 30181.3828 - val_mae: 139.6049\n",
            "Epoch 632/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 36336.4766 - mae: 156.7995 - val_loss: 28978.8066 - val_mae: 139.4810\n",
            "Epoch 633/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 32275.7598 - mae: 145.3591 - val_loss: 41494.2852 - val_mae: 170.0853\n",
            "Epoch 634/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 33442.9570 - mae: 149.4140 - val_loss: 28608.5723 - val_mae: 134.7892\n",
            "Epoch 635/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 27915.0781 - mae: 136.2334 - val_loss: 32466.0684 - val_mae: 145.0565\n",
            "Epoch 636/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 27776.1465 - mae: 136.5748 - val_loss: 23184.5234 - val_mae: 124.4306\n",
            "Epoch 637/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 47335.2188 - mae: 176.8226 - val_loss: 22954.5312 - val_mae: 122.5266\n",
            "Epoch 638/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 34527.2812 - mae: 149.6424 - val_loss: 41610.0195 - val_mae: 173.3342\n",
            "Epoch 639/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 31160.5820 - mae: 143.9185 - val_loss: 59482.7969 - val_mae: 204.0097\n",
            "Epoch 640/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 32620.0273 - mae: 144.5628 - val_loss: 24016.2969 - val_mae: 126.7563\n",
            "Epoch 641/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 22289.6172 - mae: 122.4674 - val_loss: 18114.3242 - val_mae: 111.1313\n",
            "Epoch 642/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 20193.4980 - mae: 116.4508 - val_loss: 17395.0117 - val_mae: 108.1798\n",
            "Epoch 643/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 23816.0977 - mae: 126.4791 - val_loss: 19419.6719 - val_mae: 112.2112\n",
            "Epoch 644/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 18380.1816 - mae: 111.7899 - val_loss: 21073.8203 - val_mae: 120.1080\n",
            "Epoch 645/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 16869.7246 - mae: 105.8997 - val_loss: 20291.5684 - val_mae: 116.8837\n",
            "Epoch 646/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 18812.0645 - mae: 111.4579 - val_loss: 13542.5605 - val_mae: 94.9216\n",
            "Epoch 647/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 17367.4941 - mae: 109.3529 - val_loss: 12852.4414 - val_mae: 92.8478\n",
            "Epoch 648/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 16838.4434 - mae: 105.5864 - val_loss: 47882.4609 - val_mae: 193.4449\n",
            "Epoch 649/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 22669.6504 - mae: 122.1194 - val_loss: 30362.8457 - val_mae: 144.4188\n",
            "Epoch 650/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 21367.3125 - mae: 120.2562 - val_loss: 50986.1445 - val_mae: 200.4399\n",
            "Epoch 651/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 21088.0801 - mae: 116.5317 - val_loss: 12198.3770 - val_mae: 88.4675\n",
            "Epoch 652/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 11852.2305 - mae: 90.0558 - val_loss: 14969.7363 - val_mae: 100.9302\n",
            "Epoch 653/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 12438.2783 - mae: 90.4050 - val_loss: 15107.8828 - val_mae: 99.6288\n",
            "Epoch 654/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 12840.2842 - mae: 93.1946 - val_loss: 10929.5547 - val_mae: 84.7588\n",
            "Epoch 655/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 10144.7275 - mae: 82.6742 - val_loss: 14184.3105 - val_mae: 100.8751\n",
            "Epoch 656/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 11519.3516 - mae: 87.6948 - val_loss: 13071.0518 - val_mae: 93.5482\n",
            "Epoch 657/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 9171.3828 - mae: 77.3493 - val_loss: 8091.5806 - val_mae: 72.8940\n",
            "Epoch 658/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 9677.6689 - mae: 79.2981 - val_loss: 15918.3057 - val_mae: 103.4135\n",
            "Epoch 659/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 10832.2432 - mae: 84.5137 - val_loss: 6849.7896 - val_mae: 68.6411\n",
            "Epoch 660/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 14738.9785 - mae: 98.3551 - val_loss: 9372.0908 - val_mae: 77.5996\n",
            "Epoch 661/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 10789.8184 - mae: 85.2142 - val_loss: 19658.0625 - val_mae: 119.3807\n",
            "Epoch 662/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 13065.3340 - mae: 93.4063 - val_loss: 12217.4707 - val_mae: 90.0276\n",
            "Epoch 663/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 8494.6289 - mae: 75.7299 - val_loss: 6156.1172 - val_mae: 63.4509\n",
            "Epoch 664/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 7464.1436 - mae: 70.3284 - val_loss: 6585.1895 - val_mae: 66.2996\n",
            "Epoch 665/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 5974.3975 - mae: 62.8811 - val_loss: 9840.7930 - val_mae: 80.3897\n",
            "Epoch 666/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 9408.7178 - mae: 78.3974 - val_loss: 6365.9385 - val_mae: 63.4149\n",
            "Epoch 667/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 6231.8164 - mae: 64.4795 - val_loss: 7013.6816 - val_mae: 68.0476\n",
            "Epoch 668/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 6641.8638 - mae: 67.3570 - val_loss: 9290.1631 - val_mae: 82.4780\n",
            "Epoch 669/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 5452.8867 - mae: 59.7502 - val_loss: 3657.2424 - val_mae: 50.5678\n",
            "Epoch 670/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4901.4385 - mae: 56.8553 - val_loss: 6718.1279 - val_mae: 67.3761\n",
            "Epoch 671/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3611.2366 - mae: 48.5568 - val_loss: 5945.7280 - val_mae: 63.1710\n",
            "Epoch 672/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 5400.6938 - mae: 59.5493 - val_loss: 2635.1125 - val_mae: 41.6332\n",
            "Epoch 673/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3318.0193 - mae: 46.9330 - val_loss: 3204.0200 - val_mae: 45.0385\n",
            "Epoch 674/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4409.6450 - mae: 53.7013 - val_loss: 2982.5986 - val_mae: 43.7564\n",
            "Epoch 675/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2956.9993 - mae: 44.1962 - val_loss: 2197.3955 - val_mae: 37.5172\n",
            "Epoch 676/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2602.1106 - mae: 41.3146 - val_loss: 4050.1536 - val_mae: 51.7478\n",
            "Epoch 677/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2296.1055 - mae: 39.0156 - val_loss: 2406.2427 - val_mae: 39.8671\n",
            "Epoch 678/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2596.4294 - mae: 41.5287 - val_loss: 2887.0935 - val_mae: 44.3256\n",
            "Epoch 679/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4318.5146 - mae: 54.4136 - val_loss: 7846.4795 - val_mae: 79.3685\n",
            "Epoch 680/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 5412.5850 - mae: 60.6574 - val_loss: 3262.4382 - val_mae: 47.6387\n",
            "Epoch 681/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2782.0847 - mae: 42.5377 - val_loss: 1729.2089 - val_mae: 33.8051\n",
            "Epoch 682/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1578.2424 - mae: 32.1269 - val_loss: 1249.3654 - val_mae: 28.9510\n",
            "Epoch 683/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1601.2352 - mae: 32.4704 - val_loss: 1168.1996 - val_mae: 27.9282\n",
            "Epoch 684/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2050.2795 - mae: 36.6588 - val_loss: 1460.6792 - val_mae: 32.2029\n",
            "Epoch 685/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1731.5743 - mae: 33.9816 - val_loss: 1380.9656 - val_mae: 29.9646\n",
            "Epoch 686/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1558.1564 - mae: 31.9073 - val_loss: 1005.5092 - val_mae: 25.2151\n",
            "Epoch 687/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1507.0402 - mae: 31.3454 - val_loss: 931.2585 - val_mae: 24.9820\n",
            "Epoch 688/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 940.0789 - mae: 25.1265 - val_loss: 1326.3248 - val_mae: 29.7719\n",
            "Epoch 689/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1009.6523 - mae: 25.9269 - val_loss: 1202.4540 - val_mae: 27.9733\n",
            "Epoch 690/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 848.9595 - mae: 23.7590 - val_loss: 627.5365 - val_mae: 20.3549\n",
            "Epoch 691/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1018.2980 - mae: 25.8074 - val_loss: 908.1586 - val_mae: 24.2179\n",
            "Epoch 692/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 718.2637 - mae: 21.7975 - val_loss: 937.4736 - val_mae: 24.6869\n",
            "Epoch 693/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 725.2577 - mae: 21.9366 - val_loss: 485.3378 - val_mae: 17.9909\n",
            "Epoch 694/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 662.7654 - mae: 20.8166 - val_loss: 449.8677 - val_mae: 17.3364\n",
            "Epoch 695/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 719.0939 - mae: 21.6397 - val_loss: 538.2297 - val_mae: 18.9988\n",
            "Epoch 696/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 685.2167 - mae: 21.2624 - val_loss: 773.1506 - val_mae: 22.7560\n",
            "Epoch 697/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 940.0396 - mae: 25.1703 - val_loss: 453.1055 - val_mae: 18.1104\n",
            "Epoch 698/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 613.1015 - mae: 20.3263 - val_loss: 416.2324 - val_mae: 17.2040\n",
            "Epoch 699/1000\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 623.0891 - mae: 20.4665 - val_loss: 333.8369 - val_mae: 14.9657\n",
            "Epoch 700/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 626.9078 - mae: 20.3713 - val_loss: 329.4504 - val_mae: 15.2558\n",
            "Epoch 701/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 356.2834 - mae: 15.5259 - val_loss: 709.6069 - val_mae: 23.0204\n",
            "Epoch 702/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 486.7801 - mae: 17.8922 - val_loss: 2114.9834 - val_mae: 43.6693\n",
            "Epoch 703/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 897.3798 - mae: 25.3020 - val_loss: 1534.6656 - val_mae: 36.6430\n",
            "Epoch 704/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 718.9202 - mae: 22.4357 - val_loss: 497.5893 - val_mae: 18.7015\n",
            "Epoch 705/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 704.4006 - mae: 22.5243 - val_loss: 171.5691 - val_mae: 11.1040\n",
            "Epoch 706/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 287.2868 - mae: 13.5828 - val_loss: 154.9280 - val_mae: 10.0263\n",
            "Epoch 707/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 223.0484 - mae: 12.1128 - val_loss: 791.9056 - val_mae: 25.8194\n",
            "Epoch 708/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 427.6071 - mae: 17.1989 - val_loss: 333.1792 - val_mae: 15.7450\n",
            "Epoch 709/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 288.9723 - mae: 13.8086 - val_loss: 437.1901 - val_mae: 18.3445\n",
            "Epoch 710/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 169.2282 - mae: 10.5103 - val_loss: 102.3957 - val_mae: 8.1956\n",
            "Epoch 711/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 214.0625 - mae: 12.0307 - val_loss: 311.7000 - val_mae: 15.3943\n",
            "Epoch 712/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 198.3581 - mae: 11.3617 - val_loss: 149.3043 - val_mae: 10.1430\n",
            "Epoch 713/1000\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 138.1001 - mae: 9.5473 - val_loss: 94.7647 - val_mae: 7.7614\n",
            "Epoch 714/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 109.0165 - mae: 8.3397 - val_loss: 217.8829 - val_mae: 12.8778\n",
            "Epoch 715/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 136.8177 - mae: 9.4268 - val_loss: 427.5307 - val_mae: 19.2933\n",
            "Epoch 716/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 181.1267 - mae: 11.1899 - val_loss: 145.0519 - val_mae: 10.2358\n",
            "Epoch 717/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 113.9848 - mae: 8.5135 - val_loss: 47.7205 - val_mae: 5.7000\n",
            "Epoch 718/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 368.5958 - mae: 16.5413 - val_loss: 130.9191 - val_mae: 9.4676\n",
            "Epoch 719/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 99.7645 - mae: 8.2483 - val_loss: 62.7087 - val_mae: 6.6007\n",
            "Epoch 720/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 308.9626 - mae: 15.2848 - val_loss: 135.7523 - val_mae: 10.2260\n",
            "Epoch 721/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 82.9572 - mae: 7.3825 - val_loss: 232.6746 - val_mae: 14.1670\n",
            "Epoch 722/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 195.7360 - mae: 11.4969 - val_loss: 138.7842 - val_mae: 10.5024\n",
            "Epoch 723/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 165.3244 - mae: 11.1511 - val_loss: 219.6605 - val_mae: 13.8800\n",
            "Epoch 724/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 58.3849 - mae: 6.2648 - val_loss: 47.8511 - val_mae: 5.8443\n",
            "Epoch 725/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 50.5824 - mae: 5.7543 - val_loss: 31.1941 - val_mae: 4.5906\n",
            "Epoch 726/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 302.9030 - mae: 15.3776 - val_loss: 43.9323 - val_mae: 5.2398\n",
            "Epoch 727/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 58.2504 - mae: 6.0943 - val_loss: 17.8047 - val_mae: 3.4844\n",
            "Epoch 728/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 119.2159 - mae: 9.0718 - val_loss: 22.7253 - val_mae: 3.6978\n",
            "Epoch 729/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 328.2059 - mae: 15.5341 - val_loss: 182.3767 - val_mae: 12.8469\n",
            "Epoch 730/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 800.1599 - mae: 25.7039 - val_loss: 298.2483 - val_mae: 16.4636\n",
            "Epoch 731/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 719.9633 - mae: 22.3653 - val_loss: 1368.7401 - val_mae: 36.6115\n",
            "Epoch 732/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2410.6384 - mae: 41.1678 - val_loss: 17226.5156 - val_mae: 131.0582\n",
            "Epoch 733/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 152881.7969 - mae: 340.7302 - val_loss: 248341.0938 - val_mae: 494.6611\n",
            "Epoch 734/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 64343.9375 - mae: 219.2298 - val_loss: 29724.5352 - val_mae: 163.6438\n",
            "Epoch 735/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 102458.5703 - mae: 284.3997 - val_loss: 17133.3535 - val_mae: 128.3008\n",
            "Epoch 736/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 34330.6641 - mae: 157.8563 - val_loss: 88520.7109 - val_mae: 297.1567\n",
            "Epoch 737/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 20269.5234 - mae: 117.7612 - val_loss: 6150.8745 - val_mae: 77.3919\n",
            "Epoch 738/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1638.6819 - mae: 35.9267 - val_loss: 2014.2292 - val_mae: 44.7164\n",
            "Epoch 739/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2633.1975 - mae: 50.4216 - val_loss: 2365.7915 - val_mae: 48.3332\n",
            "Epoch 740/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 8334.9795 - mae: 77.5564 - val_loss: 45663.0234 - val_mae: 212.1660\n",
            "Epoch 741/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 42146.4883 - mae: 184.5060 - val_loss: 266207.4062 - val_mae: 510.9391\n",
            "Epoch 742/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 273867.4062 - mae: 482.0384 - val_loss: 10005.9023 - val_mae: 90.7128\n",
            "Epoch 743/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 16705.6465 - mae: 109.6207 - val_loss: 2166.2791 - val_mae: 42.3321\n",
            "Epoch 744/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2998.5012 - mae: 48.0675 - val_loss: 1055.8845 - val_mae: 31.8652\n",
            "Epoch 745/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 3055.2410 - mae: 50.4472 - val_loss: 1114.6451 - val_mae: 32.6426\n",
            "Epoch 746/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 16395.0996 - mae: 115.9472 - val_loss: 62483.8828 - val_mae: 249.9310\n",
            "Epoch 747/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 107058.8594 - mae: 285.0552 - val_loss: 2423.0671 - val_mae: 36.4084\n",
            "Epoch 748/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 96130.6172 - mae: 268.7751 - val_loss: 3500.3704 - val_mae: 51.4892\n",
            "Epoch 749/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 40270.6836 - mae: 192.9827 - val_loss: 16135.0186 - val_mae: 125.9771\n",
            "Epoch 750/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3451.8066 - mae: 47.5088 - val_loss: 556.6889 - val_mae: 20.4513\n",
            "Epoch 751/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 96519.0078 - mae: 222.7063 - val_loss: 665564.6250 - val_mae: 808.8346\n",
            "Epoch 752/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 338251.7812 - mae: 519.8694 - val_loss: 74408.0391 - val_mae: 265.3705\n",
            "Epoch 753/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 104894.3906 - mae: 281.9207 - val_loss: 49774.6914 - val_mae: 220.2176\n",
            "Epoch 754/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7297.9541 - mae: 62.6300 - val_loss: 746.0295 - val_mae: 23.6128\n",
            "Epoch 755/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2115.2051 - mae: 38.6393 - val_loss: 1790.9883 - val_mae: 39.7630\n",
            "Epoch 756/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3381.6443 - mae: 45.9476 - val_loss: 1780.6443 - val_mae: 42.0089\n",
            "Epoch 757/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 554.0142 - mae: 18.9592 - val_loss: 1298.5792 - val_mae: 35.9116\n",
            "Epoch 758/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1270.2791 - mae: 32.4419 - val_loss: 1917.0551 - val_mae: 43.4479\n",
            "Epoch 759/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 11513.5557 - mae: 99.3175 - val_loss: 26929.2930 - val_mae: 162.8253\n",
            "Epoch 760/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 60629.1094 - mae: 214.2801 - val_loss: 436970.5938 - val_mae: 655.5980\n",
            "Epoch 761/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 526121.9375 - mae: 649.2495 - val_loss: 242900.1719 - val_mae: 491.0194\n",
            "Epoch 762/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 36564.0312 - mae: 146.2971 - val_loss: 1119.1654 - val_mae: 30.2441\n",
            "Epoch 763/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 700.5105 - mae: 21.7962 - val_loss: 853.5148 - val_mae: 28.2423\n",
            "Epoch 764/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 297.5641 - mae: 14.6471 - val_loss: 159.2643 - val_mae: 12.3706\n",
            "Epoch 765/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 258.3781 - mae: 14.2590 - val_loss: 298.3844 - val_mae: 17.0787\n",
            "Epoch 766/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 190.3580 - mae: 12.6259 - val_loss: 8.1018 - val_mae: 2.3033\n",
            "Epoch 767/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 86.1789 - mae: 8.2552 - val_loss: 323.4645 - val_mae: 17.7542\n",
            "Epoch 768/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3223.8228 - mae: 52.1572 - val_loss: 9419.4863 - val_mae: 96.8860\n",
            "Epoch 769/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 202544.2812 - mae: 392.3001 - val_loss: 689901.1250 - val_mae: 830.1559\n",
            "Epoch 770/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 257374.6562 - mae: 447.1812 - val_loss: 61253.4844 - val_mae: 242.7431\n",
            "Epoch 771/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 200524.7812 - mae: 372.6451 - val_loss: 1031874.2500 - val_mae: 1001.1141\n",
            "Epoch 772/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 318575.1875 - mae: 459.0769 - val_loss: 9883.1611 - val_mae: 87.5684\n",
            "Epoch 773/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 17809.5352 - mae: 111.2592 - val_loss: 4537.8027 - val_mae: 64.0570\n",
            "Epoch 774/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1412.1073 - mae: 30.8938 - val_loss: 266.3925 - val_mae: 9.8948\n",
            "Epoch 775/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 635.2547 - mae: 21.3269 - val_loss: 843.9070 - val_mae: 28.3130\n",
            "Epoch 776/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 388.6953 - mae: 17.3438 - val_loss: 523.6282 - val_mae: 22.7479\n",
            "Epoch 777/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 255.6781 - mae: 13.9403 - val_loss: 40.2156 - val_mae: 5.9277\n",
            "Epoch 778/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 301.8419 - mae: 14.6258 - val_loss: 490.2748 - val_mae: 21.9406\n",
            "Epoch 779/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 83.9190 - mae: 6.3054 - val_loss: 5.6030 - val_mae: 1.8204\n",
            "Epoch 780/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 443.5346 - mae: 17.1031 - val_loss: 779.6949 - val_mae: 27.6971\n",
            "Epoch 781/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 345.6134 - mae: 15.8416 - val_loss: 488.8369 - val_mae: 21.9846\n",
            "Epoch 782/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 13707.1064 - mae: 91.4702 - val_loss: 159461.7812 - val_mae: 398.9709\n",
            "Epoch 783/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 328848.2188 - mae: 500.9714 - val_loss: 634798.0625 - val_mae: 794.4800\n",
            "Epoch 784/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 183007.8750 - mae: 367.2178 - val_loss: 24066.7422 - val_mae: 152.8026\n",
            "Epoch 785/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 14912.2354 - mae: 104.4179 - val_loss: 17597.0645 - val_mae: 131.3371\n",
            "Epoch 786/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4961.8750 - mae: 59.1764 - val_loss: 59.8155 - val_mae: 6.0324\n",
            "Epoch 787/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1037.7454 - mae: 28.8005 - val_loss: 2117.4521 - val_mae: 45.4102\n",
            "Epoch 788/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1043.2528 - mae: 27.3514 - val_loss: 4092.6843 - val_mae: 63.6815\n",
            "Epoch 789/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 24226.6992 - mae: 141.0226 - val_loss: 121741.2734 - val_mae: 348.6293\n",
            "Epoch 790/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 309255.0938 - mae: 510.2383 - val_loss: 291331.4375 - val_mae: 538.3646\n",
            "Epoch 791/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 93957.5469 - mae: 269.1230 - val_loss: 16386.2930 - val_mae: 124.5831\n",
            "Epoch 792/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 30048.1973 - mae: 144.0715 - val_loss: 68.5134 - val_mae: 7.2877\n",
            "Epoch 793/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 25196.1797 - mae: 137.6458 - val_loss: 90946.1406 - val_mae: 300.9645\n",
            "Epoch 794/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 74428.6641 - mae: 224.5097 - val_loss: 20235.9980 - val_mae: 135.2068\n",
            "Epoch 795/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 8705.3711 - mae: 78.5711 - val_loss: 479.4262 - val_mae: 11.7024\n",
            "Epoch 796/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 18475.2090 - mae: 121.8065 - val_loss: 30332.8301 - val_mae: 172.3485\n",
            "Epoch 797/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 141650.4062 - mae: 367.6220 - val_loss: 106371.0781 - val_mae: 319.5640\n",
            "Epoch 798/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 390407.8750 - mae: 538.6099 - val_loss: 259426.8906 - val_mae: 499.3125\n",
            "Epoch 799/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 180330.3594 - mae: 373.9091 - val_loss: 66959.0312 - val_mae: 258.7368\n",
            "Epoch 800/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 67020.3047 - mae: 223.5945 - val_loss: 14198.2676 - val_mae: 115.5091\n",
            "Epoch 801/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 7551.6685 - mae: 75.2264 - val_loss: 2821.6289 - val_mae: 52.2904\n",
            "Epoch 802/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1699.8715 - mae: 34.3104 - val_loss: 44.6982 - val_mae: 5.4645\n",
            "Epoch 803/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 464.3106 - mae: 18.5548 - val_loss: 298.2259 - val_mae: 17.1162\n",
            "Epoch 804/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 103.3259 - mae: 8.7480 - val_loss: 51.4658 - val_mae: 6.7848\n",
            "Epoch 805/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 65.3263 - mae: 6.6052 - val_loss: 116.1979 - val_mae: 10.1334\n",
            "Epoch 806/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 208.3166 - mae: 10.9029 - val_loss: 1946.1293 - val_mae: 44.0200\n",
            "Epoch 807/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 124160.7578 - mae: 268.9210 - val_loss: 1084382.2500 - val_mae: 1040.5223\n",
            "Epoch 808/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 481812.4062 - mae: 618.2625 - val_loss: 9533.5625 - val_mae: 97.5183\n",
            "Epoch 809/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 59791.6367 - mae: 213.5347 - val_loss: 4374.2529 - val_mae: 56.7982\n",
            "Epoch 810/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 13714.4688 - mae: 101.6248 - val_loss: 185.3584 - val_mae: 12.3825\n",
            "Epoch 811/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 2002.7799 - mae: 38.3495 - val_loss: 977.5258 - val_mae: 31.0452\n",
            "Epoch 812/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1148.7369 - mae: 30.1213 - val_loss: 1073.5907 - val_mae: 31.5671\n",
            "Epoch 813/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 3181.4890 - mae: 45.4557 - val_loss: 567.2204 - val_mae: 20.7830\n",
            "Epoch 814/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 409.7042 - mae: 18.4055 - val_loss: 671.5022 - val_mae: 25.5539\n",
            "Epoch 815/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 399.2610 - mae: 18.7621 - val_loss: 34.2736 - val_mae: 4.5858\n",
            "Epoch 816/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 15559.6289 - mae: 81.8874 - val_loss: 207341.7969 - val_mae: 454.2419\n",
            "Epoch 817/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 554635.1875 - mae: 591.0553 - val_loss: 45066.6641 - val_mae: 201.4874\n",
            "Epoch 818/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 17625.8184 - mae: 109.7784 - val_loss: 13390.3477 - val_mae: 115.0535\n",
            "Epoch 819/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 14371.6289 - mae: 103.9370 - val_loss: 7641.7368 - val_mae: 86.7037\n",
            "Epoch 820/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 2053.4802 - mae: 36.5185 - val_loss: 74.2156 - val_mae: 7.2360\n",
            "Epoch 821/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 71.9471 - mae: 7.1768 - val_loss: 41.8023 - val_mae: 4.4132\n",
            "Epoch 822/1000\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 37.4730 - mae: 4.9051 - val_loss: 189.2301 - val_mae: 13.5083\n",
            "Epoch 823/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 5253.3901 - mae: 54.8125 - val_loss: 74435.2344 - val_mae: 272.6161\n",
            "Epoch 824/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 515000.2188 - mae: 626.9532 - val_loss: 361960.1562 - val_mae: 589.2775\n",
            "Epoch 825/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 134312.6094 - mae: 310.5200 - val_loss: 139868.7344 - val_mae: 373.8097\n",
            "Epoch 826/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 39017.4336 - mae: 171.0774 - val_loss: 22743.7578 - val_mae: 150.0136\n",
            "Epoch 827/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 21131.7129 - mae: 129.0674 - val_loss: 10090.8818 - val_mae: 98.3225\n",
            "Epoch 828/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 11028.0469 - mae: 91.0312 - val_loss: 7650.2388 - val_mae: 84.2638\n",
            "Epoch 829/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4932.1753 - mae: 63.0527 - val_loss: 668.6788 - val_mae: 23.5723\n",
            "Epoch 830/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 454.8667 - mae: 18.0358 - val_loss: 3096.2063 - val_mae: 55.5654\n",
            "Epoch 831/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 5160.6416 - mae: 66.4109 - val_loss: 22.9635 - val_mae: 3.8241\n",
            "Epoch 832/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 251819.7344 - mae: 372.6894 - val_loss: 755038.7500 - val_mae: 867.5054\n",
            "Epoch 833/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 206294.0312 - mae: 393.5919 - val_loss: 153734.7969 - val_mae: 345.5733\n",
            "Epoch 834/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 385195.2500 - mae: 550.3028 - val_loss: 85137.1406 - val_mae: 287.5882\n",
            "Epoch 835/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 62387.0703 - mae: 201.0365 - val_loss: 4068.6658 - val_mae: 62.7829\n",
            "Epoch 836/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4304.0879 - mae: 53.1576 - val_loss: 514.3825 - val_mae: 22.0898\n",
            "Epoch 837/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 924.7657 - mae: 26.5924 - val_loss: 392.7758 - val_mae: 18.7356\n",
            "Epoch 838/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 399.1833 - mae: 17.4605 - val_loss: 510.4274 - val_mae: 22.3916\n",
            "Epoch 839/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 527.0302 - mae: 21.0116 - val_loss: 62.0281 - val_mae: 7.1711\n",
            "Epoch 840/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 213.6156 - mae: 12.7565 - val_loss: 8.9388 - val_mae: 2.2812\n",
            "Epoch 841/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 28.7904 - mae: 4.2895 - val_loss: 114.9072 - val_mae: 10.4637\n",
            "Epoch 842/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 127.3747 - mae: 9.9766 - val_loss: 953.0900 - val_mae: 30.7705\n",
            "Epoch 843/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 37760.9141 - mae: 136.1798 - val_loss: 532296.2500 - val_mae: 728.4114\n",
            "Epoch 844/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 608313.0625 - mae: 669.6822 - val_loss: 28877.2227 - val_mae: 168.1084\n",
            "Epoch 845/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 50974.9062 - mae: 196.3355 - val_loss: 30556.7227 - val_mae: 171.0349\n",
            "Epoch 846/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 6125.9424 - mae: 62.0488 - val_loss: 210.0590 - val_mae: 14.1009\n",
            "Epoch 847/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 269.0701 - mae: 14.1568 - val_loss: 740.4061 - val_mae: 26.7048\n",
            "Epoch 848/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 769.4824 - mae: 24.3859 - val_loss: 12.6127 - val_mae: 2.8123\n",
            "Epoch 849/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 85.5637 - mae: 7.7806 - val_loss: 415.7526 - val_mae: 20.2631\n",
            "Epoch 850/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3491.3640 - mae: 56.0734 - val_loss: 6286.8579 - val_mae: 79.1447\n",
            "Epoch 851/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 146573.2344 - mae: 330.8425 - val_loss: 598452.8125 - val_mae: 773.5359\n",
            "Epoch 852/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 151917.4531 - mae: 312.2557 - val_loss: 12090.3906 - val_mae: 107.9152\n",
            "Epoch 853/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 22983.5977 - mae: 140.8100 - val_loss: 11702.6113 - val_mae: 105.8828\n",
            "Epoch 854/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3072.6260 - mae: 48.0255 - val_loss: 4010.5105 - val_mae: 61.2639\n",
            "Epoch 855/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 16031.8350 - mae: 98.4780 - val_loss: 151093.1250 - val_mae: 388.1716\n",
            "Epoch 856/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 535043.4375 - mae: 681.7528 - val_loss: 82283.8203 - val_mae: 280.0934\n",
            "Epoch 857/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 32565.1211 - mae: 152.7685 - val_loss: 1849.7120 - val_mae: 25.2919\n",
            "Epoch 858/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2375.4321 - mae: 41.0116 - val_loss: 1126.9668 - val_mae: 29.1993\n",
            "Epoch 859/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 7000.5640 - mae: 73.8372 - val_loss: 4743.7861 - val_mae: 64.4648\n",
            "Epoch 860/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4601.1904 - mae: 58.9654 - val_loss: 1918.0079 - val_mae: 40.6699\n",
            "Epoch 861/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1989.1007 - mae: 36.8223 - val_loss: 98.6711 - val_mae: 8.6939\n",
            "Epoch 862/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 903.3770 - mae: 21.5349 - val_loss: 14167.8457 - val_mae: 118.8986\n",
            "Epoch 863/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 400311.1562 - mae: 536.8923 - val_loss: 347610.8438 - val_mae: 585.4083\n",
            "Epoch 864/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 102531.9375 - mae: 257.0667 - val_loss: 7928.5576 - val_mae: 86.1655\n",
            "Epoch 865/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 21168.5352 - mae: 124.3457 - val_loss: 6300.3262 - val_mae: 76.5410\n",
            "Epoch 866/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 7754.4546 - mae: 75.0249 - val_loss: 2405.5381 - val_mae: 44.4801\n",
            "Epoch 867/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2869.4832 - mae: 48.7219 - val_loss: 1001.3565 - val_mae: 26.1330\n",
            "Epoch 868/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 6293.0371 - mae: 67.5572 - val_loss: 24235.4082 - val_mae: 154.4269\n",
            "Epoch 869/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 139992.3438 - mae: 307.1778 - val_loss: 961156.8750 - val_mae: 980.1626\n",
            "Epoch 870/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 369748.8750 - mae: 530.5046 - val_loss: 109862.0859 - val_mae: 330.4388\n",
            "Epoch 871/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 60876.0898 - mae: 215.9738 - val_loss: 15806.8633 - val_mae: 123.9252\n",
            "Epoch 872/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 4016.5342 - mae: 55.9831 - val_loss: 114.6627 - val_mae: 8.8595\n",
            "Epoch 873/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1183.8600 - mae: 29.9668 - val_loss: 636.5893 - val_mae: 24.7871\n",
            "Epoch 874/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1055.6846 - mae: 28.3032 - val_loss: 413.6671 - val_mae: 18.1899\n",
            "Epoch 875/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 7117.7305 - mae: 80.8970 - val_loss: 7355.7881 - val_mae: 83.1635\n",
            "Epoch 876/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 20916.4102 - mae: 137.1751 - val_loss: 134357.4062 - val_mae: 365.7670\n",
            "Epoch 877/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 501208.3125 - mae: 620.4274 - val_loss: 307412.0000 - val_mae: 542.3531\n",
            "Epoch 878/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 353270.5625 - mae: 525.3649 - val_loss: 80770.2031 - val_mae: 207.0920\n",
            "Epoch 879/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 64459.9180 - mae: 216.8173 - val_loss: 6248.3091 - val_mae: 62.4229\n",
            "Epoch 880/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 8082.0552 - mae: 73.7443 - val_loss: 3578.7488 - val_mae: 59.1577\n",
            "Epoch 881/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1022.6445 - mae: 26.9749 - val_loss: 773.4404 - val_mae: 26.3428\n",
            "Epoch 882/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 550.7498 - mae: 19.9830 - val_loss: 547.6329 - val_mae: 23.2076\n",
            "Epoch 883/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 329.3047 - mae: 16.2997 - val_loss: 1022.4759 - val_mae: 31.7115\n",
            "Epoch 884/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 542.3993 - mae: 20.5559 - val_loss: 1166.7855 - val_mae: 33.6344\n",
            "Epoch 885/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 798.8914 - mae: 25.8386 - val_loss: 975.1265 - val_mae: 30.9260\n",
            "Epoch 886/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 749.7977 - mae: 24.7022 - val_loss: 1040.7063 - val_mae: 31.9196\n",
            "Epoch 887/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 161226.5000 - mae: 311.4667 - val_loss: 592886.1875 - val_mae: 768.8024\n",
            "Epoch 888/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 182776.0000 - mae: 355.4126 - val_loss: 623794.0625 - val_mae: 780.3903\n",
            "Epoch 889/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 185365.8281 - mae: 364.8309 - val_loss: 105066.1094 - val_mae: 312.4027\n",
            "Epoch 890/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 57328.7578 - mae: 213.4151 - val_loss: 5277.3403 - val_mae: 70.4925\n",
            "Epoch 891/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 33845.2305 - mae: 159.1794 - val_loss: 2458.1426 - val_mae: 47.6932\n",
            "Epoch 892/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2804.8276 - mae: 48.1244 - val_loss: 5366.3071 - val_mae: 72.0920\n",
            "Epoch 893/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1117.6237 - mae: 27.3884 - val_loss: 2391.9836 - val_mae: 48.0975\n",
            "Epoch 894/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3304.2913 - mae: 56.0024 - val_loss: 90.5970 - val_mae: 8.1463\n",
            "Epoch 895/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 33955.5352 - mae: 138.6310 - val_loss: 326105.2188 - val_mae: 569.9542\n",
            "Epoch 896/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 624629.4375 - mae: 698.5600 - val_loss: 136538.3281 - val_mae: 353.2261\n",
            "Epoch 897/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 79403.5703 - mae: 234.7766 - val_loss: 8085.4370 - val_mae: 88.3929\n",
            "Epoch 898/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2864.7117 - mae: 40.4241 - val_loss: 4233.7310 - val_mae: 60.5235\n",
            "Epoch 899/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4304.0605 - mae: 58.4890 - val_loss: 603.3009 - val_mae: 22.6358\n",
            "Epoch 900/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 753.0060 - mae: 22.7247 - val_loss: 889.7148 - val_mae: 29.5020\n",
            "Epoch 901/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1037.6533 - mae: 29.0950 - val_loss: 116.1219 - val_mae: 9.8825\n",
            "Epoch 902/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 891.5458 - mae: 26.8954 - val_loss: 2069.2056 - val_mae: 44.9401\n",
            "Epoch 903/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 15837.1836 - mae: 106.9731 - val_loss: 73451.0000 - val_mae: 270.6523\n",
            "Epoch 904/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 306287.0938 - mae: 499.7674 - val_loss: 225395.7031 - val_mae: 470.9289\n",
            "Epoch 905/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 379384.7500 - mae: 540.8345 - val_loss: 950536.5000 - val_mae: 974.8448\n",
            "Epoch 906/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 381229.0000 - mae: 533.4394 - val_loss: 37568.1914 - val_mae: 191.4971\n",
            "Epoch 907/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 20160.7871 - mae: 112.1715 - val_loss: 544.2161 - val_mae: 15.0622\n",
            "Epoch 908/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3717.3022 - mae: 52.7415 - val_loss: 1512.4120 - val_mae: 37.0906\n",
            "Epoch 909/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1497.8298 - mae: 33.3289 - val_loss: 290.4624 - val_mae: 11.9537\n",
            "Epoch 910/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 580.1058 - mae: 19.8005 - val_loss: 678.8114 - val_mae: 25.8123\n",
            "Epoch 911/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 252.4795 - mae: 13.3555 - val_loss: 144.5315 - val_mae: 11.6342\n",
            "Epoch 912/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 63.2566 - mae: 6.8979 - val_loss: 77.7996 - val_mae: 8.4211\n",
            "Epoch 913/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 109.0116 - mae: 8.6980 - val_loss: 867.2722 - val_mae: 29.3350\n",
            "Epoch 914/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1348.7299 - mae: 33.4128 - val_loss: 388.6422 - val_mae: 19.3325\n",
            "Epoch 915/1000\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 3587.8818 - mae: 53.2600 - val_loss: 1619.3231 - val_mae: 37.5044\n",
            "Epoch 916/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 69940.3438 - mae: 183.6125 - val_loss: 583881.9375 - val_mae: 763.0020\n",
            "Epoch 917/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 232090.2812 - mae: 410.4247 - val_loss: 8692.7695 - val_mae: 58.4101\n",
            "Epoch 918/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 64216.6172 - mae: 221.0751 - val_loss: 130332.6406 - val_mae: 360.4245\n",
            "Epoch 919/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 47719.0312 - mae: 186.9023 - val_loss: 19860.8672 - val_mae: 137.6058\n",
            "Epoch 920/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 12756.8896 - mae: 89.6334 - val_loss: 5105.1172 - val_mae: 71.1443\n",
            "Epoch 921/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 182222.8750 - mae: 379.5457 - val_loss: 293649.4062 - val_mae: 534.6598\n",
            "Epoch 922/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 141832.2812 - mae: 342.1972 - val_loss: 1838.3340 - val_mae: 31.8857\n",
            "Epoch 923/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 18365.9492 - mae: 116.8914 - val_loss: 11117.6621 - val_mae: 103.6874\n",
            "Epoch 924/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 7965.5942 - mae: 70.2335 - val_loss: 97.5934 - val_mae: 6.8450\n",
            "Epoch 925/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 8846.4541 - mae: 64.6738 - val_loss: 78765.5625 - val_mae: 280.0512\n",
            "Epoch 926/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 267184.8125 - mae: 469.3197 - val_loss: 437137.7500 - val_mae: 659.3391\n",
            "Epoch 927/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 196784.2969 - mae: 375.1220 - val_loss: 212767.4375 - val_mae: 460.2502\n",
            "Epoch 928/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 42548.4180 - mae: 172.8792 - val_loss: 35169.6641 - val_mae: 186.6161\n",
            "Epoch 929/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 11125.2090 - mae: 87.2232 - val_loss: 2804.2207 - val_mae: 48.3071\n",
            "Epoch 930/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4966.7974 - mae: 64.2972 - val_loss: 1150.0665 - val_mae: 25.6098\n",
            "Epoch 931/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 8909.5986 - mae: 90.6283 - val_loss: 27921.7773 - val_mae: 167.0097\n",
            "Epoch 932/1000\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 89398.1328 - mae: 265.0119 - val_loss: 106871.9141 - val_mae: 320.7038\n",
            "Epoch 933/1000\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 231712.5781 - mae: 442.3085 - val_loss: 30633.3242 - val_mae: 152.2719\n",
            "Epoch 934/1000\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 148158.3125 - mae: 339.3483 - val_loss: 37297.3008 - val_mae: 189.1777\n",
            "Epoch 935/1000\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 18958.6250 - mae: 120.9611 - val_loss: 28181.6836 - val_mae: 166.6898\n",
            "Epoch 936/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 20353.8379 - mae: 125.2605 - val_loss: 38997.0156 - val_mae: 196.8836\n",
            "Epoch 937/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 10793.9785 - mae: 86.1751 - val_loss: 25927.9355 - val_mae: 160.3608\n",
            "Epoch 938/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 113017.2891 - mae: 321.8300 - val_loss: 69537.9453 - val_mae: 260.1683\n",
            "Epoch 939/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 48334.3555 - mae: 214.1738 - val_loss: 68290.0703 - val_mae: 259.4723\n",
            "Epoch 940/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 51166.9453 - mae: 213.1968 - val_loss: 221800.0312 - val_mae: 470.0751\n",
            "Epoch 941/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 436561.7500 - mae: 582.6335 - val_loss: 49081.7148 - val_mae: 219.4665\n",
            "Epoch 942/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 13253.9482 - mae: 89.8459 - val_loss: 6394.4399 - val_mae: 79.2317\n",
            "Epoch 943/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1474.4769 - mae: 32.5492 - val_loss: 2638.2979 - val_mae: 51.2800\n",
            "Epoch 944/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 945.7720 - mae: 26.2722 - val_loss: 629.5670 - val_mae: 24.9113\n",
            "Epoch 945/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 504.6420 - mae: 19.8966 - val_loss: 1140.9615 - val_mae: 32.6247\n",
            "Epoch 946/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 7382.7817 - mae: 67.2710 - val_loss: 65881.7188 - val_mae: 256.4756\n",
            "Epoch 947/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 357663.5938 - mae: 555.5736 - val_loss: 326271.3125 - val_mae: 569.9731\n",
            "Epoch 948/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 246151.4062 - mae: 372.1463 - val_loss: 86859.6016 - val_mae: 287.6075\n",
            "Epoch 949/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 28646.0117 - mae: 147.6967 - val_loss: 13555.3818 - val_mae: 115.9894\n",
            "Epoch 950/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2438.5676 - mae: 41.8914 - val_loss: 60.7412 - val_mae: 6.4771\n",
            "Epoch 951/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1746.9543 - mae: 36.5056 - val_loss: 889.0037 - val_mae: 29.5311\n",
            "Epoch 952/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 198.7541 - mae: 11.8135 - val_loss: 615.2393 - val_mae: 24.6449\n",
            "Epoch 953/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1859.2765 - mae: 42.0597 - val_loss: 7299.1929 - val_mae: 85.2065\n",
            "Epoch 954/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 245925.0469 - mae: 439.6322 - val_loss: 324630.5312 - val_mae: 566.9512\n",
            "Epoch 955/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 76485.3047 - mae: 234.5788 - val_loss: 16907.2598 - val_mae: 124.1237\n",
            "Epoch 956/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 23524.6406 - mae: 134.1774 - val_loss: 29160.3281 - val_mae: 170.1973\n",
            "Epoch 957/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 51888.9570 - mae: 199.5276 - val_loss: 207705.5000 - val_mae: 454.9690\n",
            "Epoch 958/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 110925.5156 - mae: 298.5778 - val_loss: 158082.9062 - val_mae: 392.4712\n",
            "Epoch 959/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 273183.1875 - mae: 429.0422 - val_loss: 105229.1172 - val_mae: 311.1857\n",
            "Epoch 960/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 18348.6562 - mae: 107.9978 - val_loss: 4017.8770 - val_mae: 62.0737\n",
            "Epoch 961/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 11598.2500 - mae: 97.7177 - val_loss: 6662.0625 - val_mae: 80.2891\n",
            "Epoch 962/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2221.9070 - mae: 41.6082 - val_loss: 4695.4756 - val_mae: 67.5602\n",
            "Epoch 963/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 781.0551 - mae: 21.5935 - val_loss: 748.7156 - val_mae: 27.1500\n",
            "Epoch 964/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 10334.8984 - mae: 78.3005 - val_loss: 98199.4297 - val_mae: 311.7422\n",
            "Epoch 965/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 639386.3750 - mae: 732.2050 - val_loss: 404901.1562 - val_mae: 630.8530\n",
            "Epoch 966/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 173201.8438 - mae: 354.0588 - val_loss: 208990.5312 - val_mae: 453.8725\n",
            "Epoch 967/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 174039.1094 - mae: 357.4977 - val_loss: 65104.1016 - val_mae: 240.6356\n",
            "Epoch 968/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 33377.4180 - mae: 148.0337 - val_loss: 420.0064 - val_mae: 17.2107\n",
            "Epoch 969/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2474.6150 - mae: 43.4104 - val_loss: 3011.0066 - val_mae: 53.3811\n",
            "Epoch 970/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1953.2761 - mae: 38.8639 - val_loss: 1094.1257 - val_mae: 32.5679\n",
            "Epoch 971/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 788.2791 - mae: 23.3229 - val_loss: 399.4411 - val_mae: 19.8218\n",
            "Epoch 972/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 156.9361 - mae: 10.0827 - val_loss: 19.0511 - val_mae: 3.3916\n",
            "Epoch 973/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 119.4768 - mae: 9.5559 - val_loss: 121.1845 - val_mae: 10.4609\n",
            "Epoch 974/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 211.5236 - mae: 13.0673 - val_loss: 437.2688 - val_mae: 19.6627\n",
            "Epoch 975/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3299.5095 - mae: 49.6564 - val_loss: 6367.0688 - val_mae: 78.9529\n",
            "Epoch 976/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 146946.3750 - mae: 290.9799 - val_loss: 1224347.1250 - val_mae: 1105.0635\n",
            "Epoch 977/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 339527.7188 - mae: 468.0060 - val_loss: 79757.4688 - val_mae: 281.3112\n",
            "Epoch 978/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 19559.4648 - mae: 105.9412 - val_loss: 3673.4319 - val_mae: 54.5063\n",
            "Epoch 979/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 5581.2632 - mae: 66.0666 - val_loss: 5614.3535 - val_mae: 74.7379\n",
            "Epoch 980/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 5327.6021 - mae: 65.2989 - val_loss: 127.2675 - val_mae: 10.9784\n",
            "Epoch 981/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3762.9282 - mae: 53.1855 - val_loss: 8846.0508 - val_mae: 91.8637\n",
            "Epoch 982/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6054.9185 - mae: 71.5484 - val_loss: 3940.6516 - val_mae: 59.5882\n",
            "Epoch 983/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 299799.9688 - mae: 402.3573 - val_loss: 803232.7500 - val_mae: 892.5510\n",
            "Epoch 984/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 279342.7188 - mae: 453.1649 - val_loss: 153018.0000 - val_mae: 390.3427\n",
            "Epoch 985/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 66478.8594 - mae: 216.4732 - val_loss: 14883.5586 - val_mae: 117.4751\n",
            "Epoch 986/1000\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 21520.0332 - mae: 134.8440 - val_loss: 12191.9932 - val_mae: 106.9908\n",
            "Epoch 987/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 13445.5840 - mae: 101.1833 - val_loss: 2302.0378 - val_mae: 45.0893\n",
            "Epoch 988/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 9301.1582 - mae: 80.4390 - val_loss: 3494.4568 - val_mae: 58.7106\n",
            "Epoch 989/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 994.3070 - mae: 27.3766 - val_loss: 577.9984 - val_mae: 22.8950\n",
            "Epoch 990/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 5529.2769 - mae: 56.9058 - val_loss: 51341.6055 - val_mae: 226.5638\n",
            "Epoch 991/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 26043.9941 - mae: 147.3613 - val_loss: 20355.9531 - val_mae: 132.2847\n",
            "Epoch 992/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 449943.0312 - mae: 574.1487 - val_loss: 576620.4375 - val_mae: 755.6277\n",
            "Epoch 993/1000\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 230435.7500 - mae: 419.1051 - val_loss: 52753.7188 - val_mae: 221.8026\n",
            "Epoch 994/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 14850.6162 - mae: 103.7904 - val_loss: 326.7518 - val_mae: 9.8888\n",
            "Epoch 995/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 6574.0933 - mae: 69.6760 - val_loss: 1414.1748 - val_mae: 34.4814\n",
            "Epoch 996/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 949.9739 - mae: 26.8292 - val_loss: 209.3245 - val_mae: 13.5452\n",
            "Epoch 997/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1005.5800 - mae: 28.3008 - val_loss: 780.2146 - val_mae: 26.2960\n",
            "Epoch 998/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2126.3887 - mae: 38.5644 - val_loss: 1442.1799 - val_mae: 37.4925\n",
            "Epoch 999/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3086.7371 - mae: 50.6141 - val_loss: 4503.3906 - val_mae: 66.4612\n",
            "Epoch 1000/1000\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 224354.5156 - mae: 372.2695 - val_loss: 960001.5625 - val_mae: 977.1686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron"
      ],
      "metadata": {
        "id": "h3AqWotnZXLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron"
      ],
      "metadata": {
        "id": "F6nsDhrvYYLP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Perceptron(random_state=26)\n",
        "model1.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "uer37BMTYcii",
        "outputId": "c0315fa6-5f66-425e-8679-c1a1264d0a90"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(random_state=26)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(random_state=26)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(random_state=26)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model1.predict(X_test)"
      ],
      "metadata": {
        "id": "xQPqqXrwYiBx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "97ub4GdCY6u4"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_pred, y_test)\n",
        "print('acurácia :', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmz8e1RIYlaD",
        "outputId": "ac52af94-66f2-4af8-edc3-4bcf413fa7e3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acurácia : 0.893569844789357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multilayer Perceptron"
      ],
      "metadata": {
        "id": "OiZ6UoTpZUFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "UN2-VG7pZBkI"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1_000, random_state=26)\n",
        "model2.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "2othRnzgZEIj",
        "outputId": "e9e8161b-76f7-4319-9b75-8acbfa2f5d48"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=26)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=26)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000, random_state=26)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model2.predict(X_test)"
      ],
      "metadata": {
        "id": "qcjjtcblZHg4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_pred, y_test)\n",
        "print('acurácia :', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sokHVZuAZNpx",
        "outputId": "a4d481d8-ade0-4305-f4ea-ad001ce5e6bc"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acurácia : 0.8381374722838137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link](https://www.kaggle.com/code/leomauro/redes-neurais-classifica-o-de-cogumelos/notebook)"
      ],
      "metadata": {
        "id": "O4vwMylPZr9w"
      }
    }
  ]
}